import os
import logging
import time
import asyncio
import random
import datetime
from typing import Dict, Any, Optional, Union, List, Tuple
import functools

from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.constants import ParseMode
from telegram.ext import ContextTypes
from telegram.error import TimedOut, NetworkError

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
import token_storage
from utils import process_token_data, format_enhanced_message, format_number
from error_helpers import handle_exception
from api_cache import get_token_info_from_api
from http_client import http_client
from notifications import add_growth_notification
from token_monitor_strategy import token_monitor_strategy

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç Telegram
_telegram_context = None

def set_telegram_context(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç Telegram.
    
    Args:
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç Telegram
    """
    global _telegram_context
    _telegram_context = context

def get_telegram_context() -> Optional[ContextTypes.DEFAULT_TYPE]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç Telegram.
    
    Returns:
        –ö–æ–Ω—Ç–µ–∫—Å—Ç Telegram –∏–ª–∏ None
    """
    return _telegram_context

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–µ", notify_user=True)
async def get_token_info(
    query: str, 
    chat_id: Optional[int], 
    message_id: Optional[int] = None, 
    context: Optional[ContextTypes.DEFAULT_TYPE] = None,
    force_refresh: bool = False  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä force_refresh
) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    logger.info(f"–ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–µ: {query}, force_refresh: {force_refresh}")
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
    stored_data = token_storage.get_token_data(query)
    
    token_data = None
    token_info = None
    need_fresh_data = force_refresh  # –ï—Å–ª–∏ force_refresh=True, –≤—Å–µ–≥–¥–∞ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
    
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    if stored_data and 'token_info' in stored_data and not force_refresh:
        last_update_time = stored_data.get('last_update_time', 0)
        current_time = time.time()
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª—è–ª–∏—Å—å –º–µ–Ω–µ–µ 1 –º–∏–Ω—É—Ç—ã –Ω–∞–∑–∞–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        if current_time - last_update_time < 60:  # 60 —Å–µ–∫—É–Ω–¥ = 1 –º–∏–Ω—É—Ç–∞
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ {query}")
            token_info = stored_data['token_info']
            # –¢–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º raw_api_data, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            token_data = stored_data.get('raw_api_data')
        else:
            logger.info(f"–î–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ {query} —É—Å—Ç–∞—Ä–µ–ª–∏, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–≤–µ–∂–∏–µ")
            need_fresh_data = True
    else:
        if force_refresh:
            logger.info(f"–ó–∞–ø—Ä–æ—à–µ–Ω–æ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–∫–µ–Ω–µ {query}")
        else:
            logger.info(f"–î–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ {query} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å API")
        need_fresh_data = True
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω—ã —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏—Ö –∏–∑ API
    if need_fresh_data:
        api_data = await fetch_token_api_data(query)
        if not api_data:
            return await handle_api_error(query, chat_id, message_id, context)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ API
        token_data, token_info = process_api_data(api_data)
        if not token_info:
            return await handle_api_error(query, chat_id, message_id, context)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    initial_data = get_initial_data(query, token_info)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = format_enhanced_message(token_info, initial_data)
    
    # –ë–æ–ª—å—à–µ –Ω–µ —Å–æ–∑–¥–∞—ë–º –∫–Ω–æ–ø–∫—É Refresh –≤ –æ–¥–∏–Ω–æ—á–Ω–æ–º –æ–∫–Ω–µ
    reply_markup = None
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ chat_id
    if context and chat_id:
        await send_or_update_message(
            query, chat_id, message_id, context, message, reply_markup, token_data, token_info, initial_data
        )
    return token_info

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö API")
async def fetch_token_api_data(query: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ –∏–∑ API —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è."""
    from config import DEXSCREENER_API_URL
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    api_data = get_token_info_from_api(query)
    
    if api_data:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ API –¥–ª—è {query}")
        return api_data
    
    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ API –¥–ª—è {query}")
    return None

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö API")
def process_api_data(api_data: Dict[str, Any]) -> Tuple[Dict[str, Any], Optional[Dict[str, Any]]]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –æ—Ç API."""
    pairs = api_data.get('pairs', [])
    
    if not pairs:
        return {}, None
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π
    token_data = pairs[0]
    raw_api_data = token_data
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Ñ—É–Ω–∫—Ü–∏–∏
    token_info = process_token_data(token_data)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ token_info
    token_info['price_usd'] = token_data.get('priceUsd')  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∫—É—Ä—Å
    
    if 'txns' in token_data:
        token_info['txns'] = token_data.get('txns', {})
        
    if 'labels' in token_data:
        token_info['labels'] = token_data.get('labels', [])
        
    if 'audit' in token_data:
        token_info['audit'] = token_data.get('audit', {})
        
    if 'pyr' in token_data:
        token_info['pyr'] = token_data.get('pyr')
    
    return raw_api_data, token_info

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–∫–∏ API")
async def handle_api_error(
    query: str, 
    chat_id: Optional[int], 
    message_id: Optional[int], 
    context: Optional[ContextTypes.DEFAULT_TYPE]
) -> Optional[Dict[str, Any]]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏ API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ö—Ä–∞–Ω—è—â–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å."""
    stored_data = token_storage.get_token_data(query)
    
    if stored_data and 'token_info' in stored_data:
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å context –∏ chat_id, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        if context and chat_id:
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ '{query}'. –ü–æ–∫–∞–∑—ã–≤–∞—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
            )
        
        return stored_data.get('token_info')
    
    if context and chat_id:
        if message_id:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id,
                text=f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ '{query}'."
            )
        else:
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ '{query}'."
            )
    
    return None

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
def get_initial_data(query: str, token_info: Dict[str, Any]) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ."""
    stored_data = token_storage.get_token_data(query)
    
    if stored_data and 'initial_data' in stored_data:
        return stored_data.get('initial_data')
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ–∑–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ
    current_time = datetime.datetime.now().strftime("%H:%M:%S")
    initial_data = {
        'time': current_time,
        'market_cap': token_info['market_cap'],
        'raw_market_cap': token_info['raw_market_cap'],
        'price_usd': token_info.get('price_usd', 0)
    }
    
    logger.info(f"–ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω {query} –¥–æ–±–∞–≤–ª–µ–Ω —Å –Ω–∞—á–∞–ª—å–Ω—ã–º Market Cap: {token_info['market_cap']}")
    
    return initial_data

@handle_exception(log_msg="Error sending/updating message")
async def send_or_update_message(
    query: str,
    chat_id: int,
    message_id: Optional[int],
    context: ContextTypes.DEFAULT_TYPE,
    message: str,
    reply_markup: InlineKeyboardMarkup,
    token_data: Dict[str, Any],
    token_info: Dict[str, Any],
    initial_data: Dict[str, Any]
) -> None:
    """Sends new message or updates existing one."""
    if message_id:
        try:
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=message_id,
                text=message,
                parse_mode=ParseMode.MARKDOWN,
                reply_markup=reply_markup,
                disable_web_page_preview=True
            )
            
            # Update data in storage with same message_id
            token_data_to_store = {
                'last_update_time': time.time(),
                'message_id': message_id,  # Keep existing message_id
                'chat_id': chat_id,
                'initial_data': initial_data,
                'token_info': token_info,
                'last_alert_multiplier': token_storage.get_token_data(query).get('last_alert_multiplier', 1) if token_storage.get_token_data(query) else 1,
                'added_time': token_storage.get_token_data(query).get('added_time', time.time()) if token_storage.get_token_data(query) else time.time(),
                'raw_api_data': token_data,
                'current_price_usd': token_info.get('price_usd', 0)
            }
            
            token_storage.store_token_data(query, token_data_to_store)
            
            
        except Exception as e:
            if "Message is not modified" not in str(e):
                logger.error(f"Error updating message: {e}")
    else:
        try:
            # Send to admin first
            sent_msg = await context.bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode=ParseMode.MARKDOWN,
                reply_markup=reply_markup,
                disable_web_page_preview=True
            )
            
            # NEW: Send to ALL recipients (admin + authorized users)
            from handlers.auth_middleware import get_user_db
            from config import CONTROL_ADMIN_IDS
            user_db = get_user_db()
            all_users = user_db.get_all_users()
            active_users = [user for user in all_users if user['is_active']]
            
            # Create list of all recipients
            recipients = []
            
            # Add active users (excluding admin to avoid duplicate - admin already got message above)
            for user in active_users:
                if user['user_id'] not in CONTROL_ADMIN_IDS:  # Skip admin (already sent above)
                    recipients.append(user)
            
            # Send to all recipients
            for user in recipients:
                try:
                    await context.bot.send_message(
                        chat_id=user['user_id'],
                        text=message,
                        parse_mode=ParseMode.MARKDOWN,
                        disable_web_page_preview=True
                    )
                    logger.info(f"New token info sent to user {user['user_id']}")
                except Exception as e:
                    logger.error(f"Error sending new token to user {user['user_id']}: {e}")
            
            # Save token data with admin's message_id
            token_data_to_store = {
                'last_update_time': time.time(),
                'message_id': sent_msg.message_id,
                'chat_id': sent_msg.chat_id,
                'initial_data': initial_data,
                'token_info': token_info,
                'last_alert_multiplier': 1,
                'added_time': time.time(),
                'raw_api_data': token_data,
                'current_price_usd': token_info.get('price_usd', 0)
            }
            
            token_storage.store_token_data(query, token_data_to_store)
            if token_data:  # token_data - —ç—Ç–æ raw API –¥–∞–Ω–Ω—ã–µ
                save_raw_api_data_to_tracker_db(query, token_data)

            logger.info(f"Sent new message for token {query} (message_id: {sent_msg.message_id})")
            
        except Exception as e:
            logger.error(f"Error sending new message: {e}")

def save_raw_api_data_to_tracker_db(contract_address: str, raw_api_data: dict):
    """
    –ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ raw API –¥–∞–Ω–Ω—ã—Ö –≤ tracker –ë–î.
    """
    try:
        import json
        import sqlite3
        
        logger.info(f"üîç –û–¢–õ–ê–î–ö–ê: –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–ø–∏—Å–∞—Ç—å API –¥–∞–Ω–Ω—ã–µ –¥–ª—è {contract_address}")
        logger.info(f"üîç –û–¢–õ–ê–î–ö–ê: –†–∞–∑–º–µ—Ä API –¥–∞–Ω–Ω—ã—Ö: {len(str(raw_api_data))} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ tracker –ë–î
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–æ–∫–µ–Ω –≤ tracker –ë–î
        cursor.execute('SELECT contract FROM tokens WHERE contract = ?', (contract_address,))
        exists = cursor.fetchone()
        
        if not exists:
            logger.error(f"‚ùå –û–¢–õ–ê–î–ö–ê: –¢–æ–∫–µ–Ω {contract_address} –ù–ï –ù–ê–ô–î–ï–ù –≤ tracker –ë–î!")
            conn.close()
            return
        
        logger.info(f"‚úÖ –û–¢–õ–ê–î–ö–ê: –¢–æ–∫–µ–Ω {contract_address} –Ω–∞–π–¥–µ–Ω –≤ tracker –ë–î")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ JSON
        raw_api_json = json.dumps(raw_api_data, ensure_ascii=False)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
        cursor.execute('''
        UPDATE tokens 
        SET raw_api_data = ?
        WHERE contract = ?
        ''', (raw_api_json, contract_address))
        
        logger.info(f"üîç –û–¢–õ–ê–î–ö–ê: cursor.rowcount = {cursor.rowcount}")
        
        conn.commit()
        conn.close()
        
        if cursor.rowcount > 0:
            logger.info(f"‚úÖ Raw API –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ tracker –ë–î –¥–ª—è {contract_address}")
        else:
            logger.warning(f"‚ö†Ô∏è –¢–æ–∫–µ–Ω {contract_address} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ tracker –ë–î")
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ tracker –ë–î: {e}")
        import traceback
        logger.error(traceback.format_exc())

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–¥—Ä–µ—Å–∞ —Ç–æ–∫–µ–Ω–∞")
async def process_token_address(address: str, chat_id: int, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –æ—Ç –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–¥—Ä–µ—Å–∞ —Ç–æ–∫–µ–Ω–∞: {address}")
    
    try:
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        msg = await context.bot.send_message(
            chat_id=chat_id,
            text=f"–ü–æ–ª—É—á–µ–Ω –Ω–æ–≤—ã–π –∫–æ–Ω—Ç—Ä–∞–∫—Ç: {address}\n–ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ..."
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –æ–± —ç—Ç–æ–º —Ç–æ–∫–µ–Ω–µ
        stored_data = token_storage.get_token_data(address)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è—Ö
        set_telegram_context(context)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ
        result = await get_token_info(address, chat_id, stored_data.get('message_id') if stored_data else None, context)
        
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–∫–µ–Ω–∞ {address}: {'—É—Å–ø–µ—à–Ω–æ' if result else '–Ω–µ —É–¥–∞–ª–æ—Å—å'}")
        
        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –ø–æ–∏—Å–∫–µ
        try:
            await msg.delete()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø–æ–∏—Å–∫–µ: {e}")
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞–¥—Ä–µ—Å–∞ —Ç–æ–∫–µ–Ω–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
        try:
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ {address}: {str(e)}"
            )
        except:
            pass

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–∞")
async def check_market_cap(
    query: str,
    chat_id: Optional[int] = None,
    message_id: Optional[int] = None,
    context: Optional[ContextTypes.DEFAULT_TYPE] = None,
    check_growth: bool = True
) -> Optional[Dict[str, Any]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–∞—Ä–∫–µ—Ç –∫–∞–ø —Ç–æ–∫–µ–Ω–∞ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–Ω–æ–∂–∏—Ç–µ–ª–∏ —Ä–æ—Å—Ç–∞.
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        stored_data = token_storage.get_token_data(query)
        if not stored_data:
            logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ {query} –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return None
        
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º API —á–µ—Ä–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        api_data = get_token_info_from_api(query)
        
        if not api_data:
            logger.warning(f"API –Ω–µ –≤–µ—Ä–Ω—É–ª–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}")
            return None
        
        pairs = api_data.get('pairs', [])
        
        if not pairs:
            logger.warning(f"API –Ω–µ –≤–µ—Ä–Ω—É–ª–æ –¥–∞–Ω–Ω—ã–µ –æ –ø–∞—Ä–∞—Ö –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}")
            return None
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        token_data = pairs[0]
        
        # –ü–æ–ª—É—á–∞–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º market cap
        market_cap = token_data.get('fdv')
        raw_market_cap = market_cap
        market_cap_formatted = format_number(market_cap)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        if 'token_info' in stored_data:
            stored_data['token_info']['market_cap'] = market_cap_formatted
            stored_data['token_info']['raw_market_cap'] = raw_market_cap
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            stored_data['last_update_time'] = time.time()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            token_storage.store_token_data(query, stored_data)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º ATH, –µ—Å–ª–∏ —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—ã—à–µ
            if raw_market_cap:
                token_storage.update_token_ath(query, raw_market_cap)
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            result = {
                'market_cap': market_cap_formatted,
                'raw_market_cap': raw_market_cap
            }
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–æ—Å—Ç, –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            if check_growth:
                send_notification = False
                current_multiplier = 1
                multiplier = 1  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º multiplier –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                
                initial_data = stored_data.get('initial_data', {})
                initial_mcap = initial_data.get('raw_market_cap', 0)
                
                if initial_mcap and initial_mcap > 0 and raw_market_cap:
                    # –í—ã—á–∏—Å–ª—è–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
                    multiplier = raw_market_cap / initial_mcap
                    current_multiplier = int(multiplier)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–ª–µ—Ä—Ç –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è
                    last_alert_multiplier = stored_data.get('last_alert_multiplier', 1)
                    
                    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π –º–Ω–æ–∂–∏—Ç–µ–ª—å >= 2 –∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∞–ª–µ—Ä—Ç
                    if current_multiplier >= 2 and current_multiplier > last_alert_multiplier:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                        growth_percent = (multiplier - 1) * 100
                        send_notification = token_monitor_strategy.should_notify_growth(query, growth_percent)
                        
                        if send_notification:
                            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}: x{current_multiplier} (–ø—Ä–µ–¥—ã–¥—É—â–∏–π: x{last_alert_multiplier})")
                
                result.update({
                    'multiplier': multiplier,  # –¢–µ–ø–µ—Ä—å multiplier –≤—Å–µ–≥–¥–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
                    'current_multiplier': current_multiplier,
                    'send_notification': send_notification
                })
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–∫–µ–Ω–∞ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            token_monitor_strategy.update_token_category(query, stored_data)
            
            return result
        else:
            logger.warning(f"–í —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ—Ç –ø–æ–ª—è token_info –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}")
            return None
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–∞ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}: {e}")
        return None

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ —Ç–æ–∫–µ–Ω–æ–≤")
async def monitor_token_market_caps(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –º–∞—Ä–∫–µ—Ç –∫–∞–ø —Ç–æ–∫–µ–Ω–æ–≤ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        active_tokens = token_storage.get_active_tokens()
        
        if not active_tokens:
            logger.info("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–∞")
            return
            
        logger.info(f"–ó–∞–ø—É—â–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–∞, –≤—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(active_tokens)}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ–π—á–∞—Å
        tokens_to_check = token_monitor_strategy.get_tokens_for_check(active_tokens)
        
        if not tokens_to_check:
            logger.info("–ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Ç–µ–∫—É—â–µ–º —Ü–∏–∫–ª–µ")
            return
            
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ {len(tokens_to_check)} —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ {len(active_tokens)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è—Ö
        set_telegram_context(context)
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –æ–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ä–∫–µ—Ç –∫–∞–ø –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ—Å—Ç
        for query in tokens_to_check:
            try:
                token_data = active_tokens[query]
                chat_id = token_data.get('chat_id')
                message_id = token_data.get('message_id')  # ID —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–∫–µ–Ω–µ
                
                if not chat_id or not message_id:
                    logger.warning(f"–ù–µ—Ç chat_id –∏–ª–∏ message_id –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {query}")
                    continue
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –æ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–µ
                result = await check_market_cap(query, chat_id, message_id, context, check_growth=True)
                
                if result:
                    logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞ {query}: MC={result.get('market_cap')}, Multiplier={result.get('multiplier', 1)}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ—Å—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                    if result.get('send_notification', False):
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–æ—Å—Ç–µ –∫–∞–∫ –æ—Ç–≤–µ—Ç –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–∫–µ–Ω–µ
                        current_multiplier = result.get('current_multiplier', 1)
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                        token_info = token_data.get('token_info', {})
                        ticker = token_info.get('ticker', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        market_cap = result.get('market_cap', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –∞–ª–µ—Ä—Ç –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è
                        last_alert_multiplier = token_data.get('last_alert_multiplier', 1)
                        
                        if current_multiplier > last_alert_multiplier:
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–æ—Å—Ç–µ –∫–∞–∫ –æ—Ç–≤–µ—Ç –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                            await add_growth_notification(chat_id, ticker, current_multiplier, market_cap, message_id)
                            
                            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–ª–µ—Ä—Ç
                            token_storage.update_token_field(query, 'last_alert_multiplier', current_multiplier)
                            logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–æ—Å—Ç–µ —Ç–æ–∫–µ–Ω–∞ {ticker} –¥–æ x{current_multiplier}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ API
                await asyncio.sleep(random.uniform(1.0, 2.5))
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ —Ç–æ–∫–µ–Ω–∞ {query}: {e}")
                continue
                
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –º–∞—Ä–∫–µ—Ç –∫–∞–ø–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())

@handle_exception(log_msg="Error sending token statistics")
async def send_token_stats(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Sends token statistics for the last 12 hours to ALL authorized users.
    This function runs on schedule.
    """
    logger.info("=== STARTING TOKEN STATISTICS GENERATION ===")
    
    # Get all tokens for analytics
    all_tokens = token_storage.get_all_tokens_for_analytics()
    logger.info(f"Loaded tokens for analysis: {len(all_tokens)}")
    
    if not all_tokens:
        logger.info("No tokens to generate statistics")
        return
    
    # Current time
    current_time = time.time()
    logger.info(f"Current time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Time 12 hours ago
    time_12h_ago = current_time - (12 * 60 * 60)
    logger.info(f"Time 12 hours ago: {datetime.datetime.fromtimestamp(time_12h_ago).strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Statistics counters
    total_tokens = 0
    tokens_1_5x = 0
    tokens_2x = 0
    tokens_5x = 0
    
    # List of tokens for detailed logging
    analyzed_tokens = []
    
    # Check each token
    for query, data in all_tokens.items():
        # Check if token was added within last 12 hours
        added_time = data.get('added_time', 0)
        
        if not added_time:
            logger.info(f"Token {query} has no add time, skipping")
            continue
            
        # Log token add time
        token_added_time = datetime.datetime.fromtimestamp(added_time).strftime('%Y-%m-%d %H:%M:%S')
        logger.info(f"Token {query} added: {token_added_time}")
        
        if added_time < time_12h_ago:
            logger.info(f"Token {query} added more than 12 hours ago, skipping")
            continue
            
        # Get initial market cap
        initial_mcap = 0
        if 'initial_data' in data and 'raw_market_cap' in data['initial_data']:
            initial_mcap = data['initial_data'].get('raw_market_cap', 0)
        
        # Use ATH market cap instead of current
        ath_market_cap = data.get('ath_market_cap', 0)
        
        # Log market caps
        logger.info(f"Token {query} - Initial mcap: {initial_mcap}, ATH mcap: {ath_market_cap}")
        
        # Skip tokens without market cap data
        if not initial_mcap or not ath_market_cap:
            logger.info(f"Token {query} has no market cap data, skipping")
            continue
        
        # Calculate multiplier based on ATH
        multiplier = ath_market_cap / initial_mcap if initial_mcap > 0 else 0
        logger.info(f"Token {query} - Multiplier: {multiplier:.2f}x")
        
        # Update counters - using mutually exclusive categories
        total_tokens += 1
        
        if multiplier >= 5:
            tokens_5x += 1
        elif multiplier >= 2:
            tokens_2x += 1
        elif multiplier >= 1.5:
            tokens_1_5x += 1
        
        # Add to list for detailed logging
        ticker = "Unknown"
        if 'token_info' in data and 'ticker' in data['token_info']:
            ticker = data['token_info']['ticker']
            
        analyzed_tokens.append({
            'query': query,
            'ticker': ticker,
            'added_time': token_added_time,
            'initial_mcap': initial_mcap,
            'ath_mcap': ath_market_cap,
            'multiplier': multiplier
        })
    
    # Log detailed token statistics
    logger.info(f"Analyzed tokens for last 12 hours: {total_tokens}")
    logger.info(f"Tokens with growth 1.5x to <2x: {tokens_1_5x}")
    logger.info(f"Tokens with growth 2x to <5x: {tokens_2x}")
    logger.info(f"Tokens with growth ‚â•5x: {tokens_5x}")
    
    for token in analyzed_tokens:
        logger.info(f"Token {token['ticker']} ({token['query']}): added {token['added_time']}, multiplier {token['multiplier']:.2f}x")
    
    # Generate statistics message
    if total_tokens > 0:
        # Calculate success rate (>=1.5x)
        successful_tokens = tokens_1_5x + tokens_2x + tokens_5x
        hitrate_percent = (successful_tokens / total_tokens) * 100 if total_tokens > 0 else 0
        
        # Determine symbol for success rate visualization
        hitrate_symbol = "üî¥"  # <30%
        if hitrate_percent >= 70:
            hitrate_symbol = "üü£"  # >=70%
        elif hitrate_percent >= 50:
            hitrate_symbol = "üü¢"  # >=50%
        elif hitrate_percent >= 30:
            hitrate_symbol = "üü°"  # >=30%
        
        message = (
            f"Token stats for the last 12 hours:\n"
            f"> Total tokens: {total_tokens}\n"
            f"‚îú 1.5x-2x: {tokens_1_5x}\n"
            f"‚îú 2x-5x: {tokens_2x}\n"
            f"‚îî ‚â•5x: {tokens_5x}\n\n"
            f"Hitrate: {hitrate_percent:.1f}% {hitrate_symbol} (1.5x+)"
        )
        
        # NEW: Get ALL recipients (admin + active users)
        from handlers.auth_middleware import get_user_db
        from config import CONTROL_ADMIN_IDS
        user_db = get_user_db()
        all_users = user_db.get_all_users()
        active_users = [user for user in all_users if user['is_active']]
        
        # Create list of all recipients
        recipients = []
        
        # Add admin (always receives notifications)
        for admin_id in CONTROL_ADMIN_IDS:
            recipients.append({'user_id': admin_id, 'username': 'admin'})
        
        # Add active users (excluding admin duplicate)
        for user in active_users:
            if user['user_id'] not in CONTROL_ADMIN_IDS:  # Avoid duplicate
                recipients.append(user)
        
        if not recipients:
            logger.warning("No recipients to send statistics")
            return
        
        logger.info(f"Sending statistics to {len(recipients)} recipients (admin + active users)")
        
        # Send message to ALL recipients
        success_count = 0
        for user in recipients:
            try:
                logger.info(f"Sending statistics to chat {user['user_id']}...")
                
                # Add retry handling for sending
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        await context.bot.send_message(
                            chat_id=user['user_id'],
                            text=message
                        )
                        logger.info(f"Token statistics successfully sent to chat {user['user_id']}")
                        success_count += 1
                        break
                    except (TimedOut, NetworkError) as e:
                        if attempt < max_retries - 1:
                            logger.warning(f"Timeout sending statistics to chat {user['user_id']} (attempt {attempt+1}/{max_retries}): {e}")
                            await asyncio.sleep(2)
                        else:
                            logger.error(f"Failed to send statistics to chat {user['user_id']} after {max_retries} attempts: {e}")
            except Exception as e:
                logger.error(f"Error sending statistics to chat {user['user_id']}: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        logger.info(f"Statistics successfully sent to {success_count} out of {len(recipients)} chats")
    else:
        logger.info("No tokens in last 12 hours to generate statistics")
    
    logger.info("=== TOKEN STATISTICS GENERATION COMPLETED ===")

@handle_exception(log_msg="Error sending weekly token statistics")
async def send_weekly_token_stats(context: ContextTypes.DEFAULT_TYPE) -> None:
    """
    Sends token statistics for the last 7 days to ALL authorized users.
    This function runs on schedule.
    """
    logger.info("=== STARTING WEEKLY TOKEN STATISTICS GENERATION ===")
    
    # Get all tokens for analytics
    all_tokens = token_storage.get_all_tokens_for_analytics()
    logger.info(f"Loaded tokens for weekly analysis: {len(all_tokens)}")
    
    if not all_tokens:
        logger.info("No tokens to generate weekly statistics")
        return
    
    # Current time
    current_time = time.time()
    logger.info(f"Current time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Time 7 days ago (7 * 24 * 60 * 60 seconds)
    time_7d_ago = current_time - (7 * 24 * 60 * 60)
    logger.info(f"Time 7 days ago: {datetime.datetime.fromtimestamp(time_7d_ago).strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Weekly statistics counters (–û–ë–ù–û–í–õ–ï–ù–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò)
    total_tokens = 0
    tokens_1_5x = 0    # 1.5x-2x
    tokens_2x = 0      # 2x-3x
    tokens_3x = 0      # 3x-4x
    tokens_4x = 0      # 4x-5x
    tokens_5x = 0      # 5x-10x
    tokens_10x = 0     # >10x
    
    # List of tokens for detailed logging
    analyzed_tokens = []
    
    # Check each token
    for query, data in all_tokens.items():
        # Check if token was added within last 7 days
        added_time = data.get('added_time', 0)
        
        if not added_time:
            logger.info(f"Weekly: Token {query} has no add time, skipping")
            continue
            
        # Log token add time
        token_added_time = datetime.datetime.fromtimestamp(added_time).strftime('%Y-%m-%d %H:%M:%S')
        logger.info(f"Weekly: Token {query} added: {token_added_time}")
        
        if added_time < time_7d_ago:
            logger.info(f"Weekly: Token {query} added more than 7 days ago, skipping")
            continue
            
        # Get initial market cap
        initial_mcap = 0
        if 'initial_data' in data and 'raw_market_cap' in data['initial_data']:
            initial_mcap = data['initial_data'].get('raw_market_cap', 0)
        
        # Use ATH market cap instead of current
        ath_market_cap = data.get('ath_market_cap', 0)
        
        # If no ATH data or initial data, skip
        if not initial_mcap or initial_mcap <= 0:
            logger.info(f"Weekly: Token {query} has no valid initial market cap, skipping")
            continue
            
        if not ath_market_cap or ath_market_cap <= 0:
            logger.info(f"Weekly: Token {query} has no ATH market cap data, skipping")
            continue
        
        # Calculate multiplier using ATH
        multiplier = ath_market_cap / initial_mcap
        
        # Add to total count
        total_tokens += 1
        
        # –û–ë–ù–û–í–õ–ï–ù–ù–´–ï –ö–ê–¢–ï–ì–û–†–ò–ò –†–û–°–¢–ê
        if multiplier >= 10:
            tokens_10x += 1
            category = ">10x"
        elif multiplier >= 5:
            tokens_5x += 1
            category = "5x-10x"
        elif multiplier >= 4:
            tokens_4x += 1
            category = "4x-5x"
        elif multiplier >= 3:
            tokens_3x += 1
            category = "3x-4x"
        elif multiplier >= 2:
            tokens_2x += 1
            category = "2x-3x"
        elif multiplier >= 1.5:
            tokens_1_5x += 1
            category = "1.5x-2x"
        else:
            category = "<1.5x"
        
        analyzed_tokens.append({
            'query': query,
            'multiplier': multiplier,
            'category': category,
            'initial_mcap': initial_mcap,
            'ath_mcap': ath_market_cap
        })
        
        logger.info(f"Weekly: Token {query}: {multiplier:.2f}x ({category})")
    
    if total_tokens > 0:
        # Calculate success rates for weekly stats (–≤—Å–µ —Ç–æ–∫–µ–Ω—ã –æ—Ç 1.5x+)
        successful_tokens = tokens_1_5x + tokens_2x + tokens_3x + tokens_4x + tokens_5x + tokens_10x
        hitrate_percent = (successful_tokens / total_tokens) * 100 if total_tokens > 0 else 0
        
        # Different symbol system for weekly (–ø–æ—Ä–æ–≥–∏ –¥–ª—è 1.5x+)
        hitrate_symbol = "üî¥"  # <40%
        if hitrate_percent >= 80:
            hitrate_symbol = "üü£"  # >=80%
        elif hitrate_percent >= 60:
            hitrate_symbol = "üü¢"  # >=60%
        elif hitrate_percent >= 40:
            hitrate_symbol = "üü°"  # >=40%
        
        # –û–ë–ù–û–í–õ–ï–ù–ù–û–ï –°–û–û–ë–©–ï–ù–ò–ï –° –ù–û–í–´–ú–ò –ö–ê–¢–ï–ì–û–†–ò–Ø–ú–ò
        message = (
            f"üìä Weekly Token Stats (7 days):\n"
            f"> Total tokens: {total_tokens}\n"
            f"‚îú 1.5x-2x: {tokens_1_5x}\n"
            f"‚îú 2x-3x: {tokens_2x}\n"
            f"‚îú 3x-4x: {tokens_3x}\n"
            f"‚îú 4x-5x: {tokens_4x}\n"
            f"‚îú 5x-10x: {tokens_5x}\n"
            f"‚îî >10x: {tokens_10x}\n\n"
            f"Weekly Hitrate: {hitrate_percent:.1f}% {hitrate_symbol} (1.5x+)"
        )
        
        # NEW: Get ALL recipients (admin + active users) - —Ç–∞–∫–æ–π –∂–µ –∫–æ–¥ –∫–∞–∫ –≤ 12h –≤–µ—Ä—Å–∏–∏
        from handlers.auth_middleware import get_user_db
        from config import CONTROL_ADMIN_IDS
        user_db = get_user_db()
        all_users = user_db.get_all_users()
        active_users = [user for user in all_users if user['is_active']]
        
        # Create list of all recipients
        recipients = []
        
        # Add admin (always receives notifications)
        for admin_id in CONTROL_ADMIN_IDS:
            recipients.append({'user_id': admin_id, 'username': 'admin'})
        
        # Add active users (excluding admin duplicate)
        for user in active_users:
            if user['user_id'] not in CONTROL_ADMIN_IDS:  # Avoid duplicate
                recipients.append(user)
        
        if not recipients:
            logger.warning("No recipients to send weekly statistics")
            return
        
        logger.info(f"Sending weekly statistics to {len(recipients)} recipients (admin + active users)")
        
        # Send message to ALL recipients
        success_count = 0
        for user in recipients:
            try:
                logger.info(f"Sending weekly statistics to chat {user['user_id']}...")
                
                # Add retry handling for sending
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        await context.bot.send_message(
                            chat_id=user['user_id'],
                            text=message
                        )
                        logger.info(f"Weekly token statistics successfully sent to chat {user['user_id']}")
                        success_count += 1
                        break
                    except (TimedOut, NetworkError) as e:
                        if attempt < max_retries - 1:
                            logger.warning(f"Timeout sending weekly statistics to chat {user['user_id']} (attempt {attempt+1}/{max_retries}): {e}")
                            await asyncio.sleep(2)
                        else:
                            logger.error(f"Failed to send weekly statistics to chat {user['user_id']} after {max_retries} attempts: {e}")
            except Exception as e:
                logger.error(f"Error sending weekly statistics to chat {user['user_id']}: {e}")
                import traceback
                logger.error(traceback.format_exc())
        
        logger.info(f"Weekly statistics successfully sent to {success_count} out of {len(recipients)} chats")
    else:
        logger.info("No tokens in last 7 days to generate weekly statistics")
    
    logger.info("=== WEEKLY TOKEN STATISTICS GENERATION COMPLETED ===")



# –î–æ–±–∞–≤–∏—Ç—å —Ç–∞–∫–∂–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç:
import datetime
from telegram.error import TimedOut, NetworkError

# –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Å–∏–≥–Ω–∞–ª–∞—Ö –∏–∑ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö tracker'–∞.
def get_signals_data(contract_address: str) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Å–∏–≥–Ω–∞–ª–∞—Ö –∏–∑ SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö tracker'–∞.
    
    Args:
        contract_address: –ê–¥—Ä–µ—Å –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ —Ç–æ–∫–µ–Ω–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Å–∏–≥–Ω–∞–ª–∞—Ö –∏–ª–∏ None
    """
    try:
        import sqlite3
        from datetime import datetime
        import json
        import logging
        
        logger = logging.getLogger(__name__)
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ SQLite –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö tracker'–∞
        TRACKER_DB_PATH = 'tokens_tracker_database.db'
        conn = sqlite3.connect(TRACKER_DB_PATH)
        cursor = conn.cursor()
        
        # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Å–∏–≥–Ω–∞–ª–∞—Ö
        cursor.execute('''
        SELECT channels, channel_times, first_seen 
        FROM tokens 
        WHERE contract = ?
        ''', (contract_address,))
        
        result = cursor.fetchone()
        conn.close()
        
        # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ tracker –±–∞–∑–µ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        if not result:
            logger.debug(f"–¢–æ–∫–µ–Ω {contract_address} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ tracker –±–∞–∑–µ (–¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –Ω–∞–ø—Ä—è–º—É—é)")
            return {
                'total_signals': 0,
                'channels_list': '–î–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º',
                'signal_times': []
            }
        
        channels_str, channel_times_str, first_seen = result
        
        # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –∏–∑ SQLite –±–∞–∑—ã (–ø–æ–ª—è —É–∂–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ)
        channels_str, channel_times_str, first_seen = result
        
        # –í SQLite –∫–∞–Ω–∞–ª—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞ "–∫–∞–Ω–∞–ª1, –∫–∞–Ω–∞–ª2"
        channels = channels_str.split(', ') if channels_str and channels_str.strip() else []
        
        # channel_times —Ö—Ä–∞–Ω–∏—Ç—Å—è –∫–∞–∫ JSON —Å—Ç—Ä–æ–∫–∞
        try:
            channel_times = json.loads(channel_times_str) if channel_times_str and channel_times_str.strip() else {}
        except (json.JSONDecodeError, ValueError):
            logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ channel_times –¥–ª—è {contract_address}: '{channel_times_str}'")
            channel_times = {}
        
        if not channels:
            logger.debug(f"–£ —Ç–æ–∫–µ–Ω–∞ {contract_address} –Ω–µ—Ç –∫–∞–Ω–∞–ª–æ–≤ (–¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)")
            return {
                'total_signals': 0,
                'channels_list': '–î–æ–±–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º',
                'signal_times': []
            }
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        signal_times = []
        channels_with_times = []
        
        for channel in channels:
            if channel in channel_times:
                time_str = channel_times[channel]
                try:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Ä–µ–º—è –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ HH:MM:SS –≤ –ø–æ–ª–Ω—É—é –¥–∞—Ç—É
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞—Ç—É –∏–∑ first_seen –∏–ª–∏ —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
                    if first_seen:
                        base_date = first_seen.split(' ')[0]  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—É –∏–∑ "YYYY-MM-DD HH:MM:SS"
                    else:
                        base_date = datetime.now().strftime('%Y-%m-%d')
                    
                    full_datetime = f"{base_date} {time_str}"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏
                    datetime.strptime(time_str, '%H:%M:%S')
                    
                    signal_times.append(full_datetime)
                    channels_with_times.append(f"{channel} ({time_str})")
                except ValueError:
                    # –ï—Å–ª–∏ –≤—Ä–µ–º—è –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    signal_times.append(time_str)
                    channels_with_times.append(f"{channel} ({time_str})")
            else:
                channels_with_times.append(channel)
        
        logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ —Å–∏–≥–Ω–∞–ª–∞—Ö –¥–ª—è {contract_address}: {len(channels)} –∫–∞–Ω–∞–ª–æ–≤")
        
        return {
            'total_signals': len(channels),
            'channels_list': ' | '.join(channels_with_times),
            'signal_times': signal_times
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è {contract_address}: {e}")
        return None
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è excel —Å —Ç–æ–∫–µ–Ω–∞–º–∏ 
@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")
async def generate_analytics_excel(context: ContextTypes.DEFAULT_TYPE, chat_id: int) -> None:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Excel —Ñ–∞–π–ª —Å –ü–û–õ–ù–û–ô –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –ø–æ –≤—Å–µ–º —Ç–æ–∫–µ–Ω–∞–º (–≤–∫–ª—é—á–∞—è —Å—Ç–∞—Ä—ã–µ)."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï —Ç–æ–∫–µ–Ω—ã (–≤–∫–ª—é—á–∞—è —Å—Ç–∞—Ä—à–µ 3 –¥–Ω–µ–π)
        all_tokens = token_storage.get_all_tokens_for_analytics()
        
        if not all_tokens:
            await context.bot.send_message(
                chat_id=chat_id,
                text="–ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏."
            )
            return
        
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è {len(all_tokens)} —Ç–æ–∫–µ–Ω–æ–≤ (–≤–∫–ª—é—á–∞—è —Å—Ç–∞—Ä—ã–µ)")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è Excel (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –∏ –≤ generate_excel)
        tokens_data = []
        
        for query, token_data in all_tokens.items():
            try:
                token_info = token_data.get('token_info', {})
                initial_data = token_data.get('initial_data', {})
                raw_api_data = token_data.get('raw_api_data', {})
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                def safe_float(value, default=0.0):
                    try:
                        if value is None:
                            return default
                        return float(value)
                    except (ValueError, TypeError):
                        return default
                
                def safe_int(value, default=0):
                    try:
                        if value is None:
                            return default
                        return int(value)
                    except (ValueError, TypeError):
                        return default
                
                # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–µ
                ticker = str(token_info.get('ticker', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                ticker_address = str(token_info.get('ticker_address', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                chain_id = str(token_info.get('chain_id', ''))
                pair_address = str(token_info.get('pair_address', ''))
                
                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                current_market_cap = safe_float(token_info.get('raw_market_cap'))
                initial_market_cap = safe_float(initial_data.get('raw_market_cap'))
                ath_market_cap = safe_float(token_data.get('ath_market_cap'))
                                
                # –í—ã—á–∏—Å–ª—è–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª–∏ —Ä–æ—Å—Ç–∞
                ath_multiplier = 1.0
                
                if initial_market_cap > 0 and ath_market_cap > 0:
                    ath_multiplier = round(ath_market_cap / initial_market_cap, 2)
                
                # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                added_time = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                if token_data.get('added_time'):
                    try:
                        added_time = datetime.datetime.fromtimestamp(safe_float(token_data.get('added_time'))).strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        added_time = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                
                ath_time = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                if token_data.get('ath_time'):
                    try:
                        ath_time = datetime.datetime.fromtimestamp(safe_float(token_data.get('ath_time'))).strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        ath_time = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                
                # –û–±—ä–µ–º—ã —Ç–æ—Ä–≥–æ–≤
                volume_5m = str(token_info.get('volume_5m', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                volume_1h = str(token_info.get('volume_1h', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                token_age = str(token_info.get('token_age', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'))
                
                # –î–∞–Ω–Ω—ã–µ –æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è—Ö –∏–∑ API
                txns_data = raw_api_data.get('txns', {}) if raw_api_data else {}
                buys_5m = safe_int(txns_data.get('m5', {}).get('buys', 0) if isinstance(txns_data.get('m5'), dict) else 0)
                sells_5m = safe_int(txns_data.get('m5', {}).get('sells', 0) if isinstance(txns_data.get('m5'), dict) else 0)
                buys_1h = safe_int(txns_data.get('h1', {}).get('buys', 0) if isinstance(txns_data.get('h1'), dict) else 0)
                sells_1h = safe_int(txns_data.get('h1', {}).get('sells', 0) if isinstance(txns_data.get('h1'), dict) else 0)
                buys_24h = safe_int(txns_data.get('h24', {}).get('buys', 0) if isinstance(txns_data.get('h24'), dict) else 0)
                sells_24h = safe_int(txns_data.get('h24', {}).get('sells', 0) if isinstance(txns_data.get('h24'), dict) else 0)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                dex_id = str(raw_api_data.get('dexId', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')) if raw_api_data else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                liquidity_usd = safe_float(raw_api_data.get('liquidity', {}).get('usd', 0) if raw_api_data else 0)
                                
                # –°—Å—ã–ª–∫–∏
                dexscreener_link = str(token_info.get('dexscreener_link', ''))
                axiom_link = str(token_info.get('axiom_link', ''))
                
                # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è Excel —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º —Ç–∏–ø–æ–≤
                row = {
                    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    'Ticker': ticker,
                    'DEX': dex_id,
                    'Contract Address': ticker_address,
                    'Pair Address': pair_address,
                    'Chain ID': chain_id,
                    
                    'Token Age': token_age,
                    
                    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    'Added Time': added_time,
                    'ATH Time': ath_time,
                    
                    # –¶–µ–Ω—ã –∏ –º–∞—Ä–∫–µ—Ç –∫–∞–ø
                    
                    'Initial Market Cap': format_number(initial_market_cap),
                    'ATH Market Cap': format_number(ath_market_cap),
                    'ATH Multiplier': f"{ath_multiplier}",
                    
                    'Current Market Cap': format_number(current_market_cap),
                                        
                    # –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
                    'Liquidity USD': format_number(liquidity_usd),
                                        
                    # –°–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    'Last Update': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö –∏ –≤–µ–±-—Å–∞–π—Ç–∞—Ö
                websites = []
                socials = []
                
                if isinstance(token_info.get('websites'), list):
                    websites = [str(site.get('url', '')) for site in token_info['websites'] if site.get('url')]
                
                if isinstance(token_info.get('socials'), list):
                    socials = [f"{str(social.get('type', ''))}:{str(social.get('url', ''))}" 
                              for social in token_info['socials'] if social.get('url')]
                
                row['Websites'] = ' | '.join(websites[:3]) if websites else ''
                row['Socials'] = ' | '.join(socials[:3]) if socials else ''
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ API
                if raw_api_data:
                    row['FDV'] = safe_float(raw_api_data.get('fdv', 0))
                    row['Price Native'] = safe_float(raw_api_data.get('priceNative', 0))
                    
                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã
                    price_change = raw_api_data.get('priceChange', {})
                    if isinstance(price_change, dict):
                        row['Price Change 5m'] = safe_float(price_change.get('m5', 0))
                        row['Price Change 1h'] = safe_float(price_change.get('h1', 0))
                        row['Price Change 6h'] = safe_float(price_change.get('h6', 0))
                        row['Price Change 24h'] = safe_float(price_change.get('h24', 0))
                    else:
                        row['Price Change 5m'] = 0
                        row['Price Change 1h'] = 0
                        row['Price Change 6h'] = 0
                        row['Price Change 24h'] = 0
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–∏–≥–Ω–∞–ª–∞—Ö –∏–∑ tracker –±–∞–∑—ã
                from token_service import get_signals_data
                signals_data = get_signals_data(ticker_address)
                if signals_data:
                    row['–û–±—â–µ–µ –∫–æ–ª-–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤'] = signals_data['total_signals']
                    row['–ö–∞–Ω–∞–ª—ã'] = signals_data['channels_list']
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
                    for i, signal_time in enumerate(signals_data['signal_times'], 1):
                        row[f'{i} —Å–∏–≥–Ω–∞–ª'] = signal_time
                else:
                    row['–û–±—â–µ–µ –∫–æ–ª-–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤'] = 0
                    row['–ö–∞–Ω–∞–ª—ã'] = ''
                
                tokens_data.append(row)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–∫–µ–Ω–∞ {query} –¥–ª—è –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
                
                # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å —Å –æ—à–∏–±–∫–æ–π
                tokens_data.append({
                    'Ticker': str(token_data.get('token_info', {}).get('ticker', '–û—à–∏–±–∫–∞')),
                    'Error': str(e)
                })
        
        if not tokens_data:
            await context.bot.send_message(
                chat_id=chat_id,
                text="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏."
            )
            return
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º Excel —Ñ–∞–π–ª
        import pandas as pd
        df = pd.DataFrame(tokens_data)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ATH –º–Ω–æ–∂–∏—Ç–µ–ª—é (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
        if 'ATH Multiplier' in df.columns:
            try:
                df['ATH_Multiplier_Sort'] = df['ATH Multiplier'].astype(str).str.replace('x', '').astype(float)
                df = df.sort_values('ATH_Multiplier_Sort', ascending=False)
                df = df.drop('ATH_Multiplier_Sort', axis=1)
            except Exception as sort_e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {sort_e}")
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'full_analytics_{timestamp}.xlsx'
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Excel —Ñ–∞–π–ª–∞
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Full Analytics')
            
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç –ª–∏—Å—Ç–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            worksheet = writer.sheets['Full Analytics']
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–æ–≤
            for idx, col in enumerate(df.columns):
                try:
                    max_len = max(
                        df[col].astype(str).map(len).max() if len(df) > 0 else 0,
                        len(str(col))
                    )
                    
                    col_width = min(max_len + 2, 50)
                    
                    if idx < 26:
                        col_letter = chr(65 + idx)
                    else:
                        col_letter = chr(65 + idx // 26 - 1) + chr(65 + idx % 26)
                        
                    worksheet.column_dimensions[col_letter].width = col_width
                except Exception as col_e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–∞ {idx}: {col_e}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        try:
            with open(filename, 'rb') as excel_file:
                await context.bot.send_document(
                    chat_id=chat_id, 
                    document=excel_file, 
                    caption=f"üìä Let's analyze!!! ({len(tokens_data)} tokens)"
                )
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.remove(filename)
            logger.info(f"–ü–æ–ª–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å {len(tokens_data)} —Ç–æ–∫–µ–Ω–∞–º–∏ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ñ–∞–π–ª–∞ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
            await context.bot.send_message(
                chat_id=chat_id,
                text="–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        import traceback
        logger.error(traceback.format_exc())
        await context.bot.send_message(
            chat_id=chat_id,
            text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–ª–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        )

@handle_exception(log_msg="–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
async def start_token_monitoring_system(telegram_context):
    """–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ —Å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–º."""
    try:
        # –ò–º–ø–æ—Ä—Ç—ã
        from task_scheduler import scheduler, TaskPriority
        import datetime
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á
        scheduler.start()
        logger.info("–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–¥–∞—á –∑–∞–ø—É—â–µ–Ω")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –≤ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        scheduler.schedule_task(
            "token_monitor", 
            monitor_token_market_caps, 
            delay=5,  # —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞
            interval=30,  # –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
            priority=TaskPriority.HIGH,
            context=telegram_context
        )
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        morning_time = datetime.time(8, 0, 0)  # 08:00:00
        evening_time = datetime.time(20, 0, 0)  # 20:00:00
        
        now = datetime.datetime.now().time()
        
        # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞ —É—Ç—Ä–æ–º
        morning_seconds = (
            (datetime.datetime.combine(datetime.date.today(), morning_time) - 
            datetime.datetime.combine(datetime.date.today(), now)).total_seconds()
        )
        if morning_seconds < 0:
            morning_seconds += 24 * 60 * 60  # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—Ç–∫–∏
            
        # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞ –≤–µ—á–µ—Ä–æ–º
        evening_seconds = (
            (datetime.datetime.combine(datetime.date.today(), evening_time) - 
            datetime.datetime.combine(datetime.date.today(), now)).total_seconds()
        )
        if evening_seconds < 0:
            evening_seconds += 24 * 60 * 60  # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—Ç–∫–∏
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º —É—Ç—Ä–µ–Ω–Ω—é—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        scheduler.schedule_task(
            "stats_morning", 
            send_token_stats, 
            delay=morning_seconds,  # —á–µ—Ä–µ–∑ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è
            interval=24 * 60 * 60,  # –∫–∞–∂–¥—ã–µ 24 —á–∞—Å–∞
            priority=TaskPriority.NORMAL,
            context=telegram_context
        )
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º –≤–µ—á–µ—Ä–Ω—é—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        scheduler.schedule_task(
            "stats_evening", 
            send_token_stats, 
            delay=evening_seconds,  # —á–µ—Ä–µ–∑ –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è
            interval=24 * 60 * 60,  # –∫–∞–∂–¥—ã–µ 24 —á–∞—Å–∞
            priority=TaskPriority.NORMAL,
            context=telegram_context
        )
        
        logger.info("–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–ø—É—â–µ–Ω–∞")
        return True
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
        return False