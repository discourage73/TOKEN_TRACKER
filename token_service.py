import logging
import asyncio
import aiohttp
import time
import sqlite3
import json
from typing import Dict, List, Optional, Any
from datetime import datetime

from user_database import user_db
from utils import format_enhanced_message, process_token_data
from notifications import send_growth_notification_to_user
from token_monitor_strategy import token_monitor_strategy
from batch_market_cap import batch_get_market_caps

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
service_logger = logging.getLogger('token_service')
service_logger.setLevel(logging.INFO)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Å–æ–ª—å–Ω—ã–π handler –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
if not service_logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    service_logger.addHandler(console_handler)

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–≤ –ø–∞–º—è—Ç–∏)
_monitored_tokens: Dict[str, Dict[str, Any]] = {}
_monitoring_active = False
_telegram_context = None

# ============================================================================
# –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° –¢–û–ö–ï–ù–ê–ú–ò
# ============================================================================

async def get_token_info(
    token_query: str,
    chat_id: int,
    message_id: Optional[int] = None,
    context = None,
    force_refresh: bool = False
) -> bool:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    
    Args:
        token_query: –ê–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞
        chat_id: ID —á–∞—Ç–∞
        message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏)
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞
        force_refresh: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        True –µ—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞, False –∏–Ω–∞—á–µ
    """
    try:
        service_logger.info(f"–ó–∞–ø—Ä–æ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–µ: {token_query}")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ —á–µ—Ä–µ–∑ DexScreener API
        token_data = await fetch_token_from_dexscreener(token_query)
        
        if not token_data:
            service_logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞: {token_query}")
            return False
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        processed_data = process_token_data(token_data)
        service_logger.info(f"[OK] –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {processed_data.get('ticker', 'Unknown')}")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        try:
            message_text = format_enhanced_message(processed_data)
            service_logger.info(f"[OK] –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–æ, –¥–ª–∏–Ω–∞: {len(message_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        except UnicodeEncodeError as e:
            service_logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
            # Fallback: –ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ —ç–º–æ–¥–∑–∏
            ticker = processed_data.get('ticker', 'Unknown')
            address = processed_data.get('ticker_address', 'Unknown')
            market_cap = processed_data.get('market_cap', 'Unknown')
            message_text = f"*{ticker}*\n\nAddress: `{address}`\nMarket Cap: {market_cap}"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        telegram_context = get_telegram_context()
        
        if not telegram_context:
            service_logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞")
            return False
        
        sent_message = await telegram_context.bot.send_message(
            chat_id=chat_id,
            text=message_text,
            parse_mode='Markdown',
            disable_web_page_preview=True
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–∫–µ–Ω-—Å–æ–æ–±—â–µ–Ω–∏–µ
        user_db.save_user_token_message(
            token_query=token_query,
            user_id=chat_id,
            message_id=sent_message.message_id
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        add_token_to_monitoring(token_query, processed_data)
        
        service_logger.info(f"‚úÖ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–µ {token_query} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id}")
        return True
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–∫–µ–Ω–µ: {e}")
        return False

async def fetch_token_from_dexscreener(token_address: str) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ –∏–∑ DexScreener API.
    
    Args:
        token_address: –ê–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞
        
    Returns:
        –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
        service_logger.info(f"[API] –ó–∞–ø—Ä–æ—Å –∫ DexScreener API: {url}")
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                service_logger.info(f"[API] –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞ API: {response.status}")
                
                if response.status == 200:
                    try:
                        data = await response.json()
                        service_logger.info(f"[API] JSON –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã, —Ç–∏–ø: {type(data)}")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ data –Ω–µ None
                        if data is None:
                            service_logger.error(f"[ERROR] API –≤–µ—Ä–Ω—É–ª None –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address}")
                            return None
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ data —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º
                        if not isinstance(data, dict):
                            service_logger.error(f"[ERROR] API –≤–µ—Ä–Ω—É–ª –Ω–µ —Å–ª–æ–≤–∞—Ä—å: {type(data)} –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address}")
                            service_logger.error(f"Raw data: {data}")
                            return None
                        
                        pairs = data.get('pairs', [])
                        service_logger.info(f"[API] –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {len(pairs) if pairs else 0} –ø–∞—Ä")
                        
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –ø–∞—Ä—É, –µ—Å–ª–∏ –µ—Å—Ç—å
                        if pairs and len(pairs) > 0:
                            first_pair = pairs[0]
                            symbol = first_pair.get('baseToken', {}).get('symbol', 'Unknown') if isinstance(first_pair, dict) else 'Unknown'
                            service_logger.info(f"[OK] –ù–∞–π–¥–µ–Ω–∞ –ø–∞—Ä–∞: {symbol}")
                            return first_pair
                        else:
                            service_logger.warning(f"[ERROR] –ù–µ—Ç –ø–∞—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address}")
                            service_logger.warning(f"Raw API response keys: {list(data.keys()) if isinstance(data, dict) else 'Not dict'}")
                            return None
                            
                    except Exception as json_error:
                        service_logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {json_error}")
                        response_text = await response.text()
                        service_logger.error(f"Raw response text: {response_text[:500]}")
                        return None
                else:
                    service_logger.warning(f"[ERROR] API DexScreener –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status}")
                    response_text = await response.text()
                    service_logger.warning(f"Response text: {response_text}")
                    return None
                    
    except Exception as e:
        service_logger.error(f"[ERROR] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ DexScreener API: {e}")
        import traceback
        service_logger.error(traceback.format_exc())
        return None

# ============================================================================
# –°–ò–°–¢–ï–ú–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –¢–û–ö–ï–ù–û–í
# ============================================================================

def add_token_to_monitoring(token_query: str, token_data: Dict[str, Any]) -> None:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–æ–∫–µ–Ω –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.
    
    Args:
        token_query: –ó–∞–ø—Ä–æ—Å —Ç–æ–∫–µ–Ω–∞
        token_data: –î–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ
    """
    try:
        monitoring_data = {
            'token_info': token_data,
            'initial_data': token_data.copy(),
            'added_time': time.time(),
            'first_seen': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'last_check': time.time(),
            'curr_mcap': token_data.get('raw_market_cap', 0),
            'ath_market_cap': token_data.get('raw_market_cap', 0),
            'last_alert_multiplier': 1.0
        }
        
        _monitored_tokens[token_query] = monitoring_data
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_to_mcap_monitoring(token_query, monitoring_data)
        
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü—É tokens
        save_token_info_sync(token_query)
        
        service_logger.info(f"–¢–æ–∫–µ–Ω {token_query} –¥–æ–±–∞–≤–ª–µ–Ω –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {e}")

def save_to_mcap_monitoring(token_query: str, monitoring_data: Dict[str, Any]) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ –≤ —Ç–∞–±–ª–∏—Ü—É mcap_monitoring."""
    try:
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        initial_mcap = monitoring_data.get('initial_data', {}).get('raw_market_cap', 0)
        curr_mcap = monitoring_data.get('curr_mcap', 0)
        
        cursor.execute('''
            INSERT OR REPLACE INTO mcap_monitoring 
            (contract, initial_mcap, curr_mcap, ath_mcap, ath_time, is_active)
            VALUES (?, ?, ?, ?, datetime('now', 'localtime'), 1)
        ''', (token_query, initial_mcap, curr_mcap, initial_mcap))
        
        conn.commit()
        conn.close()
        
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ mcap_monitoring: {e}")

def save_token_info_sync(token_query: str) -> None:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ —á–µ—Ä–µ–∑ API –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü—É tokens (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –µ—â–µ –Ω–µ—Ç)."""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑–µ
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        cursor.execute('SELECT token_info, raw_api_data FROM tokens WHERE contract = ?', (token_query,))
        existing_data = cursor.fetchone()
        
        if existing_data and existing_data[0] and existing_data[1]:
            service_logger.info(f"üìä –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}... —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º API –∑–∞–ø—Ä–æ—Å")
            conn.close()
            return
        
        import requests
        
        service_logger.info(f"üîç –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...")
        
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_query}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            api_data = response.json()
            pairs = api_data.get('pairs', [])
            
            if pairs:
                # –ò—â–µ–º –ª—É—á—à—É—é –ø–∞—Ä—É –ø–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                best_pair = max(pairs, key=lambda p: p.get('liquidity', {}).get('usd', 0) or 0)
                
                if best_pair and best_pair.get('baseToken', {}).get('symbol'):
                    # –°–æ–∑–¥–∞–µ–º token_info
                    token_info_data = {
                        'ticker': best_pair['baseToken']['symbol'],
                        'name': best_pair['baseToken'].get('name', ''),
                        'ticker_address': token_query,
                        'pair_address': best_pair.get('pairAddress', ''),
                        'chain_id': 'solana',
                        'market_cap': best_pair.get('marketCap', ''),
                        'liquidity': best_pair.get('liquidity', {}).get('usd', 0)
                    }
                    
                    raw_api_data_json = json.dumps(api_data, ensure_ascii=False)
                    token_info_json = json.dumps(token_info_data, ensure_ascii=False)
                    
                    cursor.execute('''
                        INSERT OR IGNORE INTO tokens 
                        (contract, token_info, raw_api_data, first_seen) 
                        VALUES (?, ?, ?, datetime('now', 'localtime'))
                    ''', (token_query, token_info_json, raw_api_data_json))
                    
                    # If record already exists but data is empty, update it
                    if cursor.rowcount == 0:
                        cursor.execute('''
                            UPDATE tokens 
                            SET token_info = ?, raw_api_data = ? 
                            WHERE contract = ? AND (token_info IS NULL OR raw_api_data IS NULL)
                        ''', (token_info_json, raw_api_data_json, token_query))
                    
                    conn.commit()
                    service_logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}... —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã -> {best_pair['baseToken']['symbol']}")
                else:
                    service_logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ baseToken –¥–ª—è {token_query[:8]}...")
            else:
                service_logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –ø–∞—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...")
        else:
            service_logger.warning(f"‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code} –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...")
            
        conn.close()
            
    except Exception as e:
        service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...: {e}")

def load_active_tokens_from_db() -> Dict[str, Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ —Ç–∞–±–ª–∏—Ü—ã mcap_monitoring —Å JOIN –∫ tokens –¥–ª—è signal_reached_time."""
    try:
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT m.contract, m.initial_mcap, m.curr_mcap, m.ath_mcap, m.updated_time, m.created_time, 
                   COALESCE(t.signal_reached_time, m.created_time) as signal_reached_time
            FROM mcap_monitoring m
            LEFT JOIN tokens t ON m.contract = t.contract
            WHERE m.is_active = 1
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        active_tokens = {}
        for row in rows:
            contract, initial_mcap, curr_mcap, ath_mcap, updated_time, created_time, signal_reached_time = row
            active_tokens[contract] = {
                'initial_mcap': initial_mcap or 0,
                'curr_mcap': curr_mcap or 0,
                'ath_mcap': ath_mcap or 0,
                'updated_time': updated_time,
                'created_time': created_time,
                'signal_reached_time': signal_reached_time or created_time  # fallback –Ω–∞ created_time
            }
        
        return active_tokens
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –ë–î: {e}")
        return {}

def update_mcap_in_db(token_query: str, curr_mcap: float, ath_mcap: float = None) -> None:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç–µ–∫—É—â–∏–π mcap —Ç–æ–∫–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
    try:
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        if ath_mcap is not None:
            # –û–±–Ω–æ–≤–ª—è–µ–º curr_mcap, ath_mcap –ò ath_time
            cursor.execute('''
                UPDATE mcap_monitoring 
                SET curr_mcap = ?, ath_mcap = ?, ath_time = datetime('now', 'localtime'), updated_time = datetime('now', 'localtime')
                WHERE contract = ?
            ''', (curr_mcap, ath_mcap, token_query))
        else:
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ curr_mcap
            cursor.execute('''
                UPDATE mcap_monitoring 
                SET curr_mcap = ?, updated_time = datetime('now', 'localtime')
                WHERE contract = ?
            ''', (curr_mcap, token_query))
        
        conn.commit()
        rows_affected = cursor.rowcount
        conn.close()
        
        if rows_affected > 0:
            service_logger.debug(f"Updated mcap for {token_query[:8]}...: ${curr_mcap:,.0f}")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ mcap –≤ –ë–î: {e}")

def deactivate_token_in_db(token_query: str) -> None:
    """–î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç is_active = 0)."""
    try:
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE mcap_monitoring 
            SET is_active = 0, updated_time = datetime('now', 'localtime')
            WHERE contract = ?
        ''', (token_query,))
        
        conn.commit()
        rows_affected = cursor.rowcount
        conn.close()
        
        if rows_affected > 0:
            service_logger.info(f"üíÄ –¢–æ–∫–µ–Ω {token_query[:8]}... –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –≤ –ë–î")
        else:
            service_logger.warning(f"‚ö†Ô∏è –¢–æ–∫–µ–Ω {token_query[:8]}... –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–∞ –≤ –ë–î: {e}")

def get_monitored_tokens() -> Dict[str, Dict[str, Any]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ."""
    return _monitored_tokens.copy()

def get_token_stats(days: int = 1) -> Dict[str, Any]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥, –æ–±—ä–µ–¥–∏–Ω—è—è –¥–∞–Ω–Ω—ã–µ –∏–∑ tokens –∏ mcap_monitoring.
    
    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (1=daily, 7=weekly, 30=monthly)
    """
    try:
        import sqlite3
        from datetime import datetime, timedelta
        
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        # –í—Ä–µ–º—è N –¥–Ω–µ–π –Ω–∞–∑–∞–¥
        period_start = datetime.now() - timedelta(days=days)
        period_start_str = period_start.strftime('%Y-%m-%d %H:%M:%S')
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –∏–∑ mcap_monitoring —Ç–∞–±–ª–∏—Ü—ã
        cursor.execute('''
            SELECT COUNT(*) FROM mcap_monitoring 
            WHERE created_time >= ?
        ''', (period_start_str,))
        new_tokens = cursor.fetchone()[0]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Å —Ä–æ—Å—Ç–æ–º –æ—Ç 1.5x –¥–æ 2x (–∏—Å–ø–æ–ª—å–∑—É–µ–º ath_mcap/initial_mcap)
        cursor.execute('''
            SELECT COUNT(*) FROM mcap_monitoring 
            WHERE (ath_mcap / initial_mcap) >= 1.5 
            AND (ath_mcap / initial_mcap) < 2 
            AND created_time >= ?
            AND initial_mcap > 0
        ''', (period_start_str,))
        growing_tokens_15x_only = cursor.fetchone()[0]
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω—ã —Å —Ä–æ—Å—Ç–æ–º >= 2x (–∏—Å–ø–æ–ª—å–∑—É–µ–º ath_mcap/initial_mcap)
        cursor.execute('''
            SELECT COUNT(*) FROM mcap_monitoring 
            WHERE (ath_mcap / initial_mcap) >= 2 
            AND created_time >= ?
            AND initial_mcap > 0
        ''', (period_start_str,))
        growing_tokens_2x = cursor.fetchone()[0]
        
        # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ —Å —Ä–æ—Å—Ç–æ–º >= 1.5x (–¥–ª—è hitrate)
        total_growing_tokens_15x = growing_tokens_15x_only + growing_tokens_2x
        
        # –í—ã—á–∏—Å–ª—è–µ–º hitrate (–ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ —Å —Ä–æ—Å—Ç–æ–º ‚â•1.5x –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º total_growing_tokens_15x –∫–æ—Ç–æ—Ä—ã–π –≤–∫–ª—é—á–∞–µ—Ç –í–°–ï —Ç–æ–∫–µ–Ω—ã ‚â•1.5x
        hitrate_percent = (total_growing_tokens_15x / new_tokens * 100) if new_tokens > 0 else 0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç–æ–≤—É—é –∏–Ω–¥–∏–∫–∞—Ü–∏—é –¥–ª—è hitrate
        hitrate_symbol = "üî¥"  # <30%
        if hitrate_percent >= 70:
            hitrate_symbol = "üü£"  # >=70%
        elif hitrate_percent >= 50:
            hitrate_symbol = "üü¢"  # >=50%
        elif hitrate_percent >= 30:
            hitrate_symbol = "üü°"  # >=30%
        
        # –í—ã—á–∏—Å–ª—è–µ–º RUG ratio - –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        cursor.execute('''
            SELECT 
                COUNT(CASE WHEN is_active = 1 THEN 1 END) as active_count,
                COUNT(*) as total_count
            FROM mcap_monitoring 
            WHERE created_time >= ?
        ''', (period_start_str,))
        result = cursor.fetchone()
        active_count, total_count = result[0], result[1]
        rug_ratio = int(((total_count - active_count) / total_count * 100)) if total_count > 0 else 0
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø —Ç–æ–∫–µ–Ω—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º–∏ –º–Ω–æ–∂–∏—Ç–µ–ª—è–º–∏ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥, –æ–±—ä–µ–¥–∏–Ω—è—è –¥–∞–Ω–Ω—ã–µ
        cursor.execute('''
            SELECT m.contract, (m.ath_mcap / m.initial_mcap) as real_multiplier, t.token_info, t.raw_api_data 
            FROM mcap_monitoring m
            LEFT JOIN tokens t ON m.contract = t.contract  
            WHERE (m.ath_mcap / m.initial_mcap) >= 2 
            AND m.created_time >= ?
            AND m.initial_mcap > 0
            ORDER BY real_multiplier DESC 
            LIMIT 5
        ''', (period_start_str,))
        
        top_tokens = []
        for row in cursor.fetchall():
            contract, multiplier, token_info, raw_api_data = row
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ticker –∏–∑ JSON token_info –∏–ª–∏ raw_api_data
            token_name = contract[:8] + '...'  # fallback
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º token_info
            if token_info:
                try:
                    info = json.loads(token_info)
                    if 'ticker' in info and info['ticker']:
                        token_name = info['ticker']
                    elif 'name' in info and info['name']:
                        token_name = info['name']
                except Exception as e:
                    service_logger.debug(f"Failed to parse token_info for {contract}: {e}")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º raw_api_data
            if token_name.endswith('...') and raw_api_data:
                try:
                    raw_data = json.loads(raw_api_data)
                    # –ò—â–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
                    if 'baseToken' in raw_data and 'symbol' in raw_data['baseToken']:
                        token_name = raw_data['baseToken']['symbol']
                    elif 'name' in raw_data:
                        token_name = raw_data['name']
                    elif 'symbol' in raw_data:
                        token_name = raw_data['symbol']
                except Exception as e:
                    service_logger.debug(f"Failed to parse raw_api_data for {contract}: {e}")
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –±—ã—Å—Ç—Ä—ã–π API –∑–∞–ø—Ä–æ—Å (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ–ø —Ç–æ–∫–µ–Ω–æ–≤)
            if token_name.endswith('...'):
                try:
                    import requests
                    url = f"https://api.dexscreener.com/latest/dex/tokens/{contract}"
                    response = requests.get(url, timeout=3)
                    if response.status_code == 200:
                        api_data = response.json()
                        pairs = api_data.get('pairs', [])
                        if pairs:
                            # –ò—â–µ–º –ª—É—á—à—É—é –ø–∞—Ä—É –ø–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                            best_pair = max(pairs, key=lambda p: p.get('liquidity', {}).get('usd', 0) or 0)
                            if best_pair and best_pair.get('baseToken', {}).get('symbol'):
                                token_name = best_pair['baseToken']['symbol']
                                service_logger.info(f"Got token name from API: {contract[:8]}... -> {token_name}")
                                
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö —Ä–∞–∑
                                try:
                                    # –°–æ–∑–¥–∞–µ–º token_info –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ª—É—á—à–µ–π –ø–∞—Ä—ã
                                    token_info_data = {
                                        'ticker': best_pair['baseToken']['symbol'],
                                        'name': best_pair['baseToken'].get('name', ''),
                                        'ticker_address': contract,
                                        'pair_address': best_pair.get('pairAddress', ''),
                                        'chain_id': 'solana',
                                        'market_cap': best_pair.get('marketCap', ''),
                                        'liquidity': best_pair.get('liquidity', {}).get('usd', 0)
                                    }
                                    
                                    # –û–±–Ω–æ–≤–ª—è–µ–º token_info –∏ raw_api_data –≤ –±–∞–∑–µ
                                    update_cursor = conn.cursor()
                                    update_cursor.execute('''
                                        UPDATE tokens 
                                        SET token_info = ?, raw_api_data = ? 
                                        WHERE contract = ?
                                    ''', (json.dumps(token_info_data), json.dumps(api_data), contract))
                                    conn.commit()
                                    
                                    service_logger.info(f"Saved token data to database: {contract[:8]}...")
                                except Exception as save_e:
                                    service_logger.error(f"Failed to save token data to database for {contract}: {save_e}")
                except Exception as e:
                    service_logger.debug(f"Failed to get token name from API for {contract}: {e}")
                
            top_tokens.append({
                'name': token_name,
                'multiplier': round(multiplier, 1) if multiplier else 1.0,
                'contract': contract
            })
        
        conn.close()
        
        return {
            'new_tokens': new_tokens,
            'growing_tokens_15x': growing_tokens_15x_only,
            'growing_tokens_2x': growing_tokens_2x,
            'hitrate_percent': hitrate_percent,
            'hitrate_symbol': hitrate_symbol,
            'rug_ratio': rug_ratio,
            'top_tokens': top_tokens
        }
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return {
            'new_tokens': 0,
            'growing_tokens_15x': 0,
            'growing_tokens_2x': 0,
            'hitrate_percent': 0,
            'hitrate_symbol': 'üî¥',
            'rug_ratio': 0,
            'top_tokens': []
        }

# –§—É–Ω–∫—Ü–∏—è get_monitoring_stats —É–¥–∞–ª–µ–Ω–∞ - –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –Ω–∏–≥–¥–µ

# ============================================================================
# –°–ò–°–¢–ï–ú–ê –ë–ê–¢–ß–ò–ù–ì –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê
# ============================================================================

async def check_tokens_batch_monitoring() -> None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–∫–µ–Ω—ã –±–∞—Ç—á–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è token_monitor_strategy –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.
    """
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        active_tokens = load_active_tokens_from_db()
        
        if not active_tokens:
            service_logger.debug("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ mcap_monitoring")
            return
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        tokens_for_strategy = {}
        for token_query, db_data in active_tokens.items():
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            tokens_for_strategy[token_query] = {
                'signal_reached_time': db_data.get('signal_reached_time'),
                'created_time': db_data.get('created_time'),
                'token_info': {'raw_market_cap': db_data.get('curr_mcap', 0)},
                'initial_data': {'raw_market_cap': db_data.get('initial_mcap', 0)},
                'hidden': False
            }
        
        # –°–Ω–∞—á–∞–ª–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for token_query, token_data in tokens_for_strategy.items():
            if token_query not in token_monitor_strategy.token_categories:
                category = token_monitor_strategy.categorize_token(token_data)
                token_monitor_strategy.token_categories[token_query] = category
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        from token_monitor_strategy import TokenCategory
        categories_stats = token_monitor_strategy.get_all_tokens_by_category()
        hot_count = len(categories_stats.get(TokenCategory.HOT, []))
        active_count = len(categories_stats.get(TokenCategory.ACTIVE, []))
        stable_count = len(categories_stats.get(TokenCategory.STABLE, []))
        inactive_count = len(categories_stats.get(TokenCategory.INACTIVE, []))
        
        service_logger.info(f"üìä –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤: üî•HOT={hot_count} ‚ö°ACTIVE={active_count} ‚öñÔ∏èSTABLE={stable_count} üò¥INACTIVE={inactive_count}")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ
        tokens_to_check = token_monitor_strategy.get_tokens_for_check(tokens_for_strategy)
        
        if not tokens_to_check:
            service_logger.info("üòå –ù–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ - –≤—Å–µ —Ç–æ–∫–µ–Ω—ã –æ–∂–∏–¥–∞—é—Ç —Å–≤–æ–∏—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —Ç–æ–∫–µ–Ω—ã –ø—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è
        tokens_preview = []
        for i, token in enumerate(tokens_to_check[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
            category = token_monitor_strategy.get_token_category(token)
            category_emoji = {"HOT": "üî•", "ACTIVE": "‚ö°", "STABLE": "‚öñÔ∏è", "INACTIVE": "üò¥"}
            emoji = category_emoji.get(category.name, "‚ùì")
            tokens_preview.append(f"{emoji}{token[:8]}...")
        
        if len(tokens_to_check) > 3:
            tokens_preview.append(f"–∏ –µ—â—ë {len(tokens_to_check) - 3}")
        
        service_logger.info(f"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –±–∞—Ç—á: –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(tokens_to_check)} –∏–∑ {len(active_tokens)} —Ç–æ–∫–µ–Ω–æ–≤")
        service_logger.info(f"üìã –ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ —Ç–æ–∫–µ–Ω—ã: {', '.join(tokens_preview)}")
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ç-–∫–∞–ø—ã –±–∞—Ç—á–µ–º —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç timeout
        try:
            market_caps = await asyncio.wait_for(
                batch_get_market_caps(tokens_to_check), 
                timeout=180.0  # 3 –º–∏–Ω—É—Ç—ã –º–∞–∫—Å–∏–º—É–º –Ω–∞ –≤–µ—Å—å –±–∞—Ç—á (—É–≤–µ–ª–∏—á–µ–Ω–æ)
            )
        except asyncio.TimeoutError:
            service_logger.warning(f"‚ö†Ô∏è TIMEOUT –ø—Ä–∏ –±–∞—Ç—á–∏–Ω–≥–µ {len(tokens_to_check)} —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞ 180s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª")
            # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è —Å—Ä–∞–∑—É, –∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            market_caps = {}
        except Exception as batch_error:
            service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–∏–Ω–≥–µ market caps: {batch_error}")
            import traceback
            service_logger.error(f"Traceback: {traceback.format_exc()}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø—É—Å—Ç—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–º–µ—Å—Ç–æ return
            market_caps = {}
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        growth_notifications = []
        
        for token_query, current_mcap in market_caps.items():
            if current_mcap is None:
                continue
            
            
            # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω –µ—Å–ª–∏ mcap < 25k
            if current_mcap < 25000:
                service_logger.warning(f"üíÄ –¢–æ–∫–µ–Ω {token_query[:8]}... –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω: mcap ${current_mcap:,.0f} < $25,000")
                deactivate_token_in_db(token_query)
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–∞–ª—å–Ω–µ–π—à—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —ç—Ç–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            token_monitor_strategy.update_check_time(token_query)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–æ–∫–µ–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            old_category = token_monitor_strategy.get_token_category(token_query)
            updated_token_data = {
                'signal_reached_time': tokens_for_strategy[token_query]['signal_reached_time'],
                'created_time': tokens_for_strategy[token_query]['created_time'],
                'token_info': {'raw_market_cap': current_mcap},
                'initial_data': {'raw_market_cap': token_data.get('initial_mcap', 0)},
                'hidden': False
            }
            token_monitor_strategy.update_token_category(token_query, updated_token_data)
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ –∏–∑ –±–∞–∑—ã
            token_data = active_tokens.get(token_query)
            if not token_data:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π ATH –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            old_ath_mcap = token_data.get('ath_mcap', 0)
            current_ath = old_ath_mcap
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º ATH
            if current_mcap > old_ath_mcap:
                # –ù–æ–≤—ã–π ATH! –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î
                current_ath = current_mcap
                update_mcap_in_db(token_query, current_mcap, current_ath)
                service_logger.info(f"üöÄ –ù–æ–≤—ã–π ATH –¥–ª—è {token_query[:8]}...: ${current_mcap:,.0f}")
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–π mcap –≤ –ë–î
                update_mcap_in_db(token_query, current_mcap)
            
            # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –õ–û–ì–ò–ö–ê ATH: —É–≤–µ–¥–æ–º–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –Ω–æ–≤–æ–º ATH –∏–ª–∏ —Ä–æ—Å—Ç–µ –æ—Ç initial_mcap
            initial_mcap = token_data.get('initial_mcap', 0)
            
            if initial_mcap and initial_mcap > 0:
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å —Ä–æ—Å—Ç–∞ –æ—Ç initial call
                growth_multiplier = current_mcap / initial_mcap
                
                # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Ü–µ–ª–æ–≥–æ —á–∏—Å–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä 4.35x -> 4x)
                current_multiplier_rounded = int(growth_multiplier)
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–Ω–æ–∂–∏—Ç–µ–ª—å >= 2x –∏ –∏–∑–º–µ–Ω–∏–ª—Å—è
                if current_multiplier_rounded >= 2:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ —É–∂–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è
                    if not await was_notification_sent(token_query, current_multiplier_rounded):
                        # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–∫–µ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞—Ç—á–∏–Ω–≥–∞, –µ—Å–ª–∏ –µ—Å—Ç—å)
                        token_ticker = token_query[:8] + '...'  # Fallback
                        
                        growth_result = {
                            'token_query': token_query,
                            'token_name': token_ticker,  # –ë—É–¥–µ–º –ø–æ–ª—É—á–∞—Ç—å —Ç–∏–∫–µ—Ä –ø–æ–∑–∂–µ
                            'current_mcap': current_mcap,
                            'initial_mcap': initial_mcap,
                            'ath_mcap': current_ath,
                            'multiplier': current_multiplier_rounded,  # –†–µ–∞–ª—å–Ω—ã–π –æ–∫—Ä—É–≥–ª–µ–Ω–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å
                            'growth_multiplier': growth_multiplier,  # –¢–æ—á–Ω—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                            'market_cap_formatted': f"${current_mcap:,.0f}" if current_mcap >= 1000 else f"${current_mcap:.2f}"
                        }
                        growth_notifications.append(growth_result)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Ä–æ—Å—Ç–µ
        growth_notifications_sent = 0
        if growth_notifications:
            await send_batch_growth_notifications(growth_notifications)
            growth_notifications_sent = len(growth_notifications)
            
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        categories_stats_final = token_monitor_strategy.get_all_tokens_by_category()
        hot_final = len(categories_stats_final.get(TokenCategory.HOT, []))
        active_final = len(categories_stats_final.get(TokenCategory.ACTIVE, []))
        stable_final = len(categories_stats_final.get(TokenCategory.STABLE, []))
        inactive_final = len(categories_stats_final.get(TokenCategory.INACTIVE, []))
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        processed_tokens = len([t for t in tokens_to_check if market_caps.get(t) is not None])
        service_logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π –±–∞—Ç—á: {processed_tokens}/{len(tokens_to_check)} —Ç–æ–∫–µ–Ω–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, {growth_notifications_sent} —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –µ—Å–ª–∏ –µ—Å—Ç—å
        if (hot_final != hot_count or active_final != active_count or 
            stable_final != stable_count or inactive_final != inactive_count):
            service_logger.info(f"üîÑ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: üî•HOT={hot_final} ‚ö°ACTIVE={active_final} ‚öñÔ∏èSTABLE={stable_final} üò¥INACTIVE={inactive_final}")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º –±–∞—Ç—á –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ: {e}")
        import traceback
        service_logger.error(f"Traceback: {traceback.format_exc()}")

def check_token_growth(
    token_query: str, 
    token_data: Dict[str, Any], 
    current_mcap: float
) -> Optional[Dict[str, Any]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–æ—Å—Ç —Ç–æ–∫–µ–Ω–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω—É–∂–Ω–æ—Å—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.
    
    Returns:
        –î–∞–Ω–Ω—ã–µ –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏–ª–∏ None
    """
    try:
        initial_mcap = token_data.get('initial_data', {}).get('raw_market_cap', 0)
        last_alert_multiplier = token_data.get('last_alert_multiplier', 1.0)
        
        if not initial_mcap or current_mcap <= 0:
            return None
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å —Ä–æ—Å—Ç–∞
        current_multiplier = current_mcap / initial_mcap
        
        # –û–±–Ω–æ–≤–ª—è–µ–º ATH –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        ath_mcap = token_data.get('ath_market_cap', initial_mcap)
        if current_mcap > ath_mcap:
            token_data['ath_market_cap'] = current_mcap
            ath_mcap = current_mcap
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–æ—Å—Ç–µ
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø—Ä–∏ 2x, 3x, 5x, 10x, 20x –∏ —Ç.–¥.
        notification_multipliers = [2, 3, 5, 10, 20, 50, 100]
        
        for multiplier in notification_multipliers:
            if (current_multiplier >= multiplier and 
                last_alert_multiplier < multiplier):
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–Ω–æ–∂–∏—Ç–µ–ª—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                token_data['last_alert_multiplier'] = multiplier
                
                return {
                    'token_query': token_query,
                    'token_name': token_data.get('token_info', {}).get('ticker', 'Unknown'),
                    'multiplier': multiplier,
                    'current_mcap': current_mcap,
                    'market_cap_formatted': f"${current_mcap:,.0f}" if current_mcap >= 1000 else f"${current_mcap:.2f}"
                }
        
        return None
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–æ—Å—Ç–∞ —Ç–æ–∫–µ–Ω–∞ {token_query}: {e}")
        return None

async def broadcast_token_to_all_users(token_query: str, token_data: Dict[str, Any]) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤–æ–º —Ç–æ–∫–µ–Ω–µ –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º."""
    try:
        service_logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å—Å—ã–ª–∫—É —Ç–æ–∫–µ–Ω–∞ {token_query} –≤—Å–µ–º –∞–∫—Ç–∏–≤–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        all_users = user_db.get_all_users()
        active_users = [user for user in all_users if user.get('is_active', False)]
        
        if not active_users:
            service_logger.warning("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏")
            return
        
        service_logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(active_users)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
        message_text = format_enhanced_message(token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞
        telegram_context = get_telegram_context()
        if not telegram_context:
            service_logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞ –¥–ª—è —Ä–∞—Å—Å—ã–ª–∫–∏")
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –∫–∞–∂–¥–æ–º—É –∞–∫—Ç–∏–≤–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        successful_sends = 0
        for user in active_users:
            user_id = user['user_id']
            try:
                sent_message = await telegram_context.bot.send_message(
                    chat_id=user_id,
                    text=message_text,
                    parse_mode='Markdown',
                    disable_web_page_preview=True
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-—Ç–æ–∫–µ–Ω-—Å–æ–æ–±—â–µ–Ω–∏–µ
                user_db.save_user_token_message(
                    token_query=token_query,
                    user_id=user_id,
                    message_id=sent_message.message_id
                )
                
                successful_sends += 1
                service_logger.info(f"‚úÖ –¢–æ–∫–µ–Ω –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏
                await asyncio.sleep(0.2)
                
            except Exception as send_error:
                service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–æ–∫–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {send_error}")
                continue
        
        service_logger.info(f"üéØ –†–∞—Å—Å—ã–ª–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_sends}/{len(active_users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ–ª—É—á–∏–ª–∏ —Ç–æ–∫–µ–Ω {token_query}")
        
        # –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ mcap_monitoring
        if successful_sends > 0:
            try:
                add_token_to_monitoring(token_query, token_data)
                service_logger.info(f"üìä –¢–æ–∫–µ–Ω {token_query} –¥–æ–±–∞–≤–ª–µ–Ω –≤ mcap_monitoring")
            except Exception as monitoring_error:
                service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: {monitoring_error}")
        
    except Exception as e:
        service_logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—Å—ã–ª–∫–µ —Ç–æ–∫–µ–Ω–∞: {e}")

async def send_batch_growth_notifications(notifications: List[Dict[str, Any]]) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Ä–æ—Å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º."""
    try:
        for notification in notifications:
            token_query = notification['token_query']
            threshold = notification['multiplier']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ –ª–∏ —É–∂–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            if await was_notification_sent(token_query, threshold):
                service_logger.debug(f"–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ {threshold}x –¥–ª—è {token_query[:8]}... —É–∂–µ –±—ã–ª–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–∫–µ—Ä —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                token_api_data = await fetch_token_from_dexscreener(token_query)
                if token_api_data:
                    from utils import process_token_data
                    processed_data = process_token_data(token_api_data)
                    token_ticker = processed_data.get('ticker', token_query[:8] + '...')
                else:
                    token_ticker = token_query[:8] + '...'
            except:
                token_ticker = token_query[:8] + '...'
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–º—è —Ç–æ–∫–µ–Ω–∞
            notification['token_name'] = token_ticker
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è —ç—Ç–æ–≥–æ —Ç–æ–∫–µ–Ω–∞
            users_for_token = user_db.get_all_users_for_token(token_query)
            
            if users_for_token:
                service_logger.info(f"üìà –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ {token_ticker} {threshold}x {len(users_for_token)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º")
                
                for user_info in users_for_token:
                    user_id = user_info['user_id']
                    token_message_id = user_info.get('token_message_id')
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
                    await send_growth_notification_to_user(
                        user_id=user_id,
                        token_name=token_ticker,
                        multiplier=threshold,
                        market_cap=notification['market_cap_formatted'],
                        token_message_id=token_message_id,
                        contract_address=token_query
                    )
                    
                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏
                    await asyncio.sleep(0.1)
                
                # –ü–æ–º–µ—á–∞–µ–º —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
                await mark_notification_sent(token_query, threshold)
                
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ batch —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {e}")

async def was_notification_sent(token_query: str, multiplier: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –±—ã–ª–æ –ª–∏ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è."""
    try:
        import sqlite3
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT last_alert_multiplier FROM mcap_monitoring 
            WHERE contract = ?
        ''', (token_query,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0]:
            last_multiplier = result[0]
            return multiplier <= last_multiplier
        
        return False
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
        return False

async def mark_notification_sent(token_query: str, multiplier: int) -> None:
    """–ü–æ–º–µ—á–∞–µ—Ç —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ –º–Ω–æ–∂–∏—Ç–µ–ª—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ."""
    try:
        import sqlite3
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE mcap_monitoring 
            SET last_alert_multiplier = ?
            WHERE contract = ?
        ''', (multiplier, token_query))
        
        conn.commit()
        conn.close()
        
        service_logger.debug(f"–ü–æ–º–µ—á–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ {multiplier}x –¥–ª—è {token_query[:8]}...")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–º–µ—Ç–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")


# ============================================================================
# –°–ò–°–¢–ï–ú–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –ó–ê–ü–£–°–ö/–û–°–¢–ê–ù–û–í–ö–ê
# ============================================================================

async def start_monitoring_system(application) -> None:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤."""
    global _monitoring_active
    
    try:
        service_logger.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        active_tokens = load_active_tokens_from_db()
        service_logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(active_tokens)} –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        
        _monitoring_active = True
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        asyncio.create_task(monitoring_loop())
        
        service_logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–ø—É—â–µ–Ω–∞")
        
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
        raise

# –§—É–Ω–∫—Ü–∏—è load_tokens_from_database —É–¥–∞–ª–µ–Ω–∞ - –±—ã–ª–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–º load_active_tokens_from_db

async def monitoring_loop() -> None:
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    consecutive_errors = 0
    max_errors = 5
    
    service_logger.info("üéØ –ó–∞–ø—É—Å–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ü–∏–∫–ª–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    while _monitoring_active:
        try:
            service_logger.debug("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ü–∏–∫–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω—ã –±–∞—Ç—á–µ–º –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            await check_tokens_batch_monitoring()
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏
            consecutive_errors = 0
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ - –º–µ–Ω—å—à–µ —á–µ–º —Ä–∞–Ω—å—à–µ, —Ç–∞–∫ –∫–∞–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–∞–º–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —á–∞—Å—Ç–æ—Ç—É
            await asyncio.sleep(20)  # 20 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            
        except asyncio.CancelledError:
            service_logger.info("üõë –¶–∏–∫–ª —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ—Ç–º–µ–Ω–µ–Ω")
            break
            
        except Exception as e:
            consecutive_errors += 1
            service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º —Ü–∏–∫–ª–µ #{consecutive_errors}: {e}")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º traceback –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—à–∏–±–∫–∏
            import traceback
            service_logger.error(f"Traceback: {traceback.format_exc()}")
            
            # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É
            if consecutive_errors >= max_errors:
                service_logger.critical(f"üö® –ö–†–ò–¢–ò–ß–ù–û: {consecutive_errors} –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥ –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ! –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É")
                await asyncio.sleep(300)  # 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö
                consecutive_errors = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            else:
                await asyncio.sleep(60)  # 1 –º–∏–Ω—É—Ç–∞ –ø—Ä–∏ –æ–±—ã—á–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
    
    service_logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–≤–µ—Ä—à–µ–Ω. _monitoring_active = {_monitoring_active}")

def stop_monitoring_system() -> None:
    """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    global _monitoring_active
    _monitoring_active = False
    service_logger.info("üõë –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ç–æ–∫–µ–Ω–æ–≤ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

async def restart_monitoring_system() -> None:
    """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    global _monitoring_active
    
    service_logger.warning("üîÑ –ü–ï–†–ï–ó–ê–ü–£–°–ö —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
    
    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É
    stop_monitoring_system()
    await asyncio.sleep(2)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—É—é
    _monitoring_active = True
    asyncio.create_task(monitoring_loop())
    service_logger.info("‚úÖ –°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ü–ï–†–ï–ó–ê–ü–£–©–ï–ù–ê")

def is_monitoring_active() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–∫—Ç–∏–≤–Ω–∞ –ª–∏ —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    return _monitoring_active

# ============================================================================
# –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –û–¢–ß–ï–¢–´
# ============================================================================

async def send_token_stats(context, days: int = 1) -> None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–∫–µ–Ω–∞–º –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞–º.
    
    Args:
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç Telegram –±–æ—Ç–∞
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (1=daily, 7=weekly, 30=monthly)
    """
    try:
        from config import CONTROL_ADMIN_IDS
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        stats = get_token_stats(days)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–µ—Ä–∏–æ–¥–∞
        if days == 1:
            title = "Daily Token Statistics"
            period_text = "(24h)"
        elif days == 7:
            title = "Weekly Token Statistics" 
            period_text = "(7d)"
        else:
            title = "Monthly Token Statistics"
            period_text = f"({days}d)"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        stats_text = (
            f"üìä {title}\n"
            f"Hitrate: {stats['hitrate_percent']:.1f}% {stats['hitrate_symbol']} (1.5x+)\n\n"
            f"> Total tokens: {stats['new_tokens']}\n"
            f"‚îú 1.5x-2x: {stats['growing_tokens_15x']}\n"
            f"‚îú ‚â•2x: {stats['growing_tokens_2x']}\n"
            f"‚îî RUG ratio: {stats['rug_ratio']}%\n\n"
            f"*üèÜTop tokens {period_text}:*\n"
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ø —Ç–æ–∫–µ–Ω—ã
        for i, token in enumerate(stats['top_tokens'][:5], 1):
            stats_text += f"{i}. {token['name']} - {token['multiplier']}x\n"
        
        stats_text += f"\n_Statistics on {datetime.now().strftime('%d.%m.%Y %H:%M')}_"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Å–µ–º –∞–¥–º–∏–Ω–∞–º
        for admin_id in CONTROL_ADMIN_IDS:
            try:
                await context.bot.send_message(
                    chat_id=admin_id,
                    text=stats_text,
                    parse_mode='Markdown'
                )
                service_logger.info(f"–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –∞–¥–º–∏–Ω—É {admin_id}")
            except Exception as e:
                service_logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∞–¥–º–∏–Ω—É {admin_id}: {e}")
                
    except Exception as e:
        service_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

async def send_daily_token_stats(context) -> None:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å - –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
    await send_token_stats(context, days=1)

# ============================================================================
# –§–£–ù–ö–¶–ò–ò –î–õ–Ø –û–ë–†–ê–¢–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
# ============================================================================

# –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
def get_daily_token_stats() -> Dict[str, Any]:
    """–û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å - –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–Ω–µ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É."""
    return get_token_stats(days=1)

def get_telegram_context():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞ (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)."""
    return _telegram_context

def set_telegram_context(context):
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ—Ç–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ token_service."""
    global _telegram_context
    _telegram_context = context

async def fetch_and_save_token_info(token_query: str) -> None:
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ —á–µ—Ä–µ–∑ API –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü—É tokens."""
    try:
        import requests
        
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_query}"
        response = requests.get(url, timeout=10)
        
        if response.status_code == 200:
            api_data = response.json()
            pairs = api_data.get('pairs', [])
            
            if pairs:
                # –ò—â–µ–º –ª—É—á—à—É—é –ø–∞—Ä—É –ø–æ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                best_pair = max(pairs, key=lambda p: p.get('liquidity', {}).get('usd', 0) or 0)
                
                if best_pair and best_pair.get('baseToken', {}).get('symbol'):
                    # –°–æ–∑–¥–∞–µ–º token_info
                    token_info_data = {
                        'ticker': best_pair['baseToken']['symbol'],
                        'name': best_pair['baseToken'].get('name', ''),
                        'ticker_address': token_query,
                        'pair_address': best_pair.get('pairAddress', ''),
                        'chain_id': 'solana',
                        'market_cap': best_pair.get('marketCap', ''),
                        'liquidity': best_pair.get('liquidity', {}).get('usd', 0)
                    }
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                    conn = sqlite3.connect("tokens_tracker_database.db")
                    cursor = conn.cursor()
                    
                    raw_api_data_json = json.dumps(api_data, ensure_ascii=False)
                    token_info_json = json.dumps(token_info_data, ensure_ascii=False)
                    
                    cursor.execute('''
                        INSERT OR REPLACE INTO tokens 
                        (contract, token_info, raw_api_data, first_seen) 
                        VALUES (?, ?, ?, datetime('now', 'localtime'))
                    ''', (token_query, token_info_json, raw_api_data_json))
                    
                    conn.commit()
                    service_logger.info(f"üìä –î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}... —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã -> {best_pair['baseToken']['symbol']}")
                    
                    conn.close()
                else:
                    service_logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ baseToken –¥–ª—è {token_query[:8]}...")
            else:
                service_logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...")
        else:
            service_logger.warning(f"‚ö†Ô∏è API –æ—à–∏–±–∫–∞ {response.status_code} –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...")
            
    except Exception as e:
        service_logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞ {token_query[:8]}...: {e}")