import datetime
from typing import Dict, Any, Optional, Union, List

import logging
logger = logging.getLogger(__name__)

def format_number(value: Union[int, float, str]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if isinstance(value, (int, float)):
        if value >= 1000000000:
            return f"${value / 1000000000:.2f}B"
        elif value >= 1000000:
            return f"${value / 1000000:.2f}M"
        elif value >= 1000:
            return f"${value / 1000:.2f}K"
        else:
            return f"${value:.2f}"
    elif isinstance(value, str):
        try:
            value = float(value)
            return format_number(value)
        except (ValueError, TypeError):
            return value
    else:
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

def format_enhanced_message(token_info: Dict[str, Any], initial_data: Optional[Dict[str, Any]] = None) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–∫–µ–Ω–µ."""
    try:
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞ –≤ Twitter/X.com
        ticker_address = token_info.get('ticker_address', '')
        twitter_search_link = f"https://twitter.com/search?q={ticker_address}"
        
        message = f"ü™ô *Ticker*: {token_info.get('ticker', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} [üîç]({twitter_search_link})\n"
        message += f"üìù *CA*: `{token_info.get('ticker_address', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}`\n\n"
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Å–∞–π—Ç—ã (–ø–µ—Ä–µ–º–µ—â–µ–Ω –≤–≤–µ—Ä—Ö)
        if 'websites' in token_info and token_info.get('websites'):
            website_links = [f"[{website.get('label', 'Website')}]({website.get('url', '')})" 
                           for website in token_info.get('websites', []) if website.get('url')]
            
            if website_links:
                message += f"üåê *Website*: {' | '.join(website_links)}\n"
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç—ã: {website_links}")
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏ (–ø–µ—Ä–µ–º–µ—â–µ–Ω –≤–≤–µ—Ä—Ö)
        if 'socials' in token_info and token_info.get('socials'):
            social_links = [f"[{social.get('type', '').capitalize()}]({social.get('url', '')})" 
                          for social in token_info.get('socials', []) if social.get('url') and social.get('type')]
            
            if social_links:
                message += f"üì± *Social*: {' | '.join(social_links)}\n\n"
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏: {social_links}")
        else:
            message += "\n"  # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å, –µ—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ü—Å–µ—Ç–µ–π
        
        current_time = datetime.datetime.now().strftime("%d.%m.%y %H:%M:%S")
        message += f"üí∞ *Market Cap*: {token_info.get('market_cap', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} | _Time: {current_time}_\n"
        
        message += f"‚è±Ô∏è *Token age*: {token_info.get('token_age', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n\n"
        
        # –ë–ª–æ–∫ —Å –æ–±—ä–µ–º–∞–º–∏ —Ç–æ—Ä–≥–æ–≤
        volumes_block = ""
        if token_info.get('volume_5m', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
            volumes_block += f"üìà *Volume (5m)*: {token_info['volume_5m']}\n"
            
        if token_info.get('volume_1h', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ":
            volumes_block += f"üìà *Volume (1h)*: {token_info['volume_1h']}\n"
        
        if volumes_block:
            message += volumes_block + "\n"
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞ –¥–ª—è —Å—Å—ã–ª–æ–∫
        ticker_address = token_info.get('ticker_address', '')
        pair_address = token_info.get('pair_address', '')
        
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ GMGN
        gmgn_link = f"https://gmgn.ai/sol/token/{ticker_address}"
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–ª–æ—â–∞–¥–∫–∏
        message += f"üîé *–°—Å—ã–ª–∫–∏*: [DexScreener]({token_info.get('dexscreener_link', '#')}) | [Axiom]({token_info.get('axiom_link', '#')}) | [GMGN]({gmgn_link})\n\n"
                               
        logger.info("–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        return message
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        return f"ü™ô *Ticker*: {token_info.get('ticker', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\nüìù *CA*: `{token_info.get('ticker_address', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}`\n\nüí∞ *Market Cap*: {token_info.get('market_cap', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n\n_–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–ª–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è_"

def calculate_token_age(timestamp: Optional[int]) -> str:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π."""
    if not timestamp:
        return "Unknown"
    
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ timestamp –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ –≤ —Å–µ–∫—É–Ω–¥—ã
        creation_time = datetime.datetime.fromtimestamp(timestamp / 1000)
        now = datetime.datetime.now()
        delta = now - creation_time
        
        days = delta.days
        hours = delta.seconds // 3600
        minutes = (delta.seconds % 3600) // 60
        
        result = []
        
        if days > 0:
            days_str = "day" if days == 1 else "days"
            result.append(f"{days} {days_str}")
        
        if hours > 0:
            hours_str = "hour" if hours == 1 else "hours"
            result.append(f"{hours} {hours_str}")
        
        if minutes > 0 and days == 0:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∏–Ω—É—Ç—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –º–µ–Ω—å—à–µ –¥–Ω—è
            minutes_str = "minute" if minutes == 1 else "minutes"
            result.append(f"{minutes} {minutes_str}")
        
        if not result:
            return "Less than a minute"
        
        return " ".join(result)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ —Ç–æ–∫–µ–Ω–∞: {e}")
        return "Unknown"

def process_token_data(token_data: Dict[str, Any]) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ."""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    base_token = token_data.get('baseToken', {})
    ticker = base_token.get('symbol', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ').upper()
    ticker_address = base_token.get('address', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
    pair_address = token_data.get('pairAddress', '')
    chain_id = token_data.get('chainId', '')
    
    # –ü–æ–ª—É—á–∞–µ–º market cap, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
    market_cap = token_data.get('fdv')
    raw_market_cap = market_cap  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    market_cap_formatted = format_number(market_cap)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫–∏
    dexscreener_link = f"https://dexscreener.com/{chain_id}/{pair_address}"
    axiom_link = f"https://axiom.trade/meme/{pair_address}"
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
    volume_data = token_data.get('volume', {})
    volume_5m = volume_data.get('m5')
    volume_1h = volume_data.get('h1')
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã
    volume_5m_formatted = format_number(volume_5m)
    volume_1h_formatted = format_number(volume_1h)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
    pair_created_at = token_data.get('pairCreatedAt')
    token_age = calculate_token_age(pair_created_at)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö –∏ —Å–∞–π—Ç–∞—Ö
    info = token_data.get('info', {})
    websites = info.get('websites', [])
    socials = info.get('socials', [])
    
    return {
        'ticker': ticker,
        'ticker_address': ticker_address,
        'pair_address': pair_address,
        'chain_id': chain_id,
        'market_cap': market_cap_formatted,
        'raw_market_cap': raw_market_cap,
        'volume_5m': volume_5m_formatted,
        'volume_1h': volume_1h_formatted,
        'token_age': token_age,
        'dexscreener_link': dexscreener_link,
        'axiom_link': axiom_link,
        'websites': websites,
        'socials': socials
    }

def format_tokens_list(tokens_data: Dict[str, Dict[str, Any]], page: int = 0, tokens_per_page: int = 10) -> tuple:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –æ—Ç ATH.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (message, total_pages, current_page)
    """
    if not tokens_data:
        return ("–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–ø–∏—Å–∫–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö.", 1, 0)
    
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫—Ä—ã—Ç—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    hidden_info = ""
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å token_storage, –µ—Å–ª–∏ –æ–Ω –µ—â–µ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
        import token_storage as ts
        hidden_tokens_count = len(ts.get_hidden_tokens())
        hidden_info = f" (—Å–∫—Ä—ã—Ç—ã—Ö: {hidden_tokens_count})" if hidden_tokens_count > 0 else ""
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–∫—Ä—ã—Ç—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
    token_info_list = []
    
    try:
        for query, data in tokens_data.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ —Ç–æ–∫–µ–Ω—ã
            if data.get('hidden', False):
                continue
                
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –Ω–∞ None
            token_info = {}
            token_info['query'] = query
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–∫–µ—Ä
            token_info['ticker'] = query
            if data.get('token_info', {}).get('ticker'):
                token_info['ticker'] = data['token_info']['ticker']
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –µ–≥–æ –≤ –ø–æ–ª–Ω—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
            token_info['initial_time'] = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            token_info['added_date'] = ""
            
            if data.get('added_time'):
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º timestamp –≤ –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
                import datetime
                added_datetime = datetime.datetime.fromtimestamp(data.get('added_time', 0))
                token_info['initial_time'] = added_datetime.strftime("%H:%M:%S")
                token_info['added_date'] = added_datetime.strftime("%Y-%m-%d")
                token_info['full_datetime'] = added_datetime.strftime("%Y-%m-%d %H:%M:%S")
            elif data.get('initial_data', {}).get('time'):
                token_info['initial_time'] = data['initial_data']['time']
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø
            token_info['initial_market_cap'] = 0
            if data.get('initial_data', {}).get('raw_market_cap'):
                token_info['initial_market_cap'] = data['initial_data']['raw_market_cap']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø
            token_info['current_market_cap'] = 0
            if data.get('token_info', {}).get('raw_market_cap'):
                token_info['current_market_cap'] = data['token_info']['raw_market_cap']
            
            # –ü–æ–ª—É—á–∞–µ–º ATH –º–∞—Ä–∫–µ—Ç –∫–∞–ø
            token_info['ath_market_cap'] = data.get('ath_market_cap', 0)
            
            # –ï—Å–ª–∏ ATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –º–µ–Ω—å—à–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–∫ ATH
            if not token_info['ath_market_cap'] or (token_info['initial_market_cap'] > token_info['ath_market_cap']):
                token_info['ath_market_cap'] = token_info['initial_market_cap']
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è ATH –∏ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            token_info['ath_percent'] = 0
            if token_info['initial_market_cap'] and token_info['ath_market_cap'] and token_info['initial_market_cap'] > 0:
                token_info['ath_percent'] = ((token_info['ath_market_cap'] / token_info['initial_market_cap']) - 1) * 100
            
            token_info['curr_percent'] = 0
            if token_info['initial_market_cap'] and token_info['current_market_cap'] and token_info['initial_market_cap'] > 0:
                token_info['curr_percent'] = ((token_info['current_market_cap'] / token_info['initial_market_cap']) - 1) * 100
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ DexScreener
            token_info['dexscreener_link'] = "#"
            if data.get('token_info', {}).get('dexscreener_link'):
                token_info['dexscreener_link'] = data['token_info']['dexscreener_link']
            
            token_info_list.append(token_info)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É —Ä–æ—Å—Ç–∞ ATH (–æ—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –∫ –Ω–∞–∏–º–µ–Ω—å—à–µ–º—É)
        token_info_list.sort(key=lambda x: x.get('ath_percent', 0), reverse=True)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", 1, 0)
    
    # –†–∞—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
    total_tokens = len(token_info_list)
    total_pages = (total_tokens + tokens_per_page - 1) // tokens_per_page  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –≤–≤–µ—Ä—Ö
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if page < 0:
        page = 0
    elif page >= total_pages and total_pages > 0:
        page = total_pages - 1
    
    # –ù–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    start_idx = page * tokens_per_page
    end_idx = min(start_idx + tokens_per_page, total_tokens)
    
    # –¢–æ–∫–µ–Ω—ã –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_tokens = token_info_list[start_idx:end_idx]
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏—è
    message = f"üìã *–°–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ ({total_tokens} —à—Ç.){hidden_info}*\n"
    message += f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1} –∏–∑ {total_pages}\n\n"
    
    # –ó–∞–≥—Ä—É–∑–∏–º tracker_db –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–æ–¥–∑–∏ —Ç–æ–∫–µ–Ω–æ–≤
    tracker_emojis = {}
    try:
        import sqlite3
        import os
        
        # –ü—É—Ç—å –∫ SQL –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–µ—Ä–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞)
        TRACKER_DB_PATH = 'tokens_tracker_database.db'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ SQL –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        if os.path.exists(TRACKER_DB_PATH):
            conn = sqlite3.connect(TRACKER_DB_PATH)
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —ç–º–æ–¥–∂–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã tokens
            cursor.execute('SELECT contract, emojis FROM tokens WHERE emojis IS NOT NULL AND emojis != ""')
            rows = cursor.fetchall()
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å —ç–º–æ–¥–∂–∏ (contract –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ query)
            for contract, emojis in rows:
                if emojis:
                    tracker_emojis[contract] = emojis
            
            conn.close()
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(tracker_emojis)} —ç–º–æ–¥–∂–∏ –∏–∑ SQL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        else:
            logger.warning(f"SQL –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö {TRACKER_DB_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —ç–º–æ–¥–∂–∏ –∏–∑ SQL: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    try:
        for i, token in enumerate(page_tokens, start=start_idx + 1):
            ticker = token.get('ticker', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            query = token.get('query', '')
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
            if token.get('full_datetime'):
                date_time_str = token.get('full_datetime')
            else:
                added_date = token.get('added_date', '')
                initial_time = token.get('initial_time', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                date_time_str = f"{added_date} {initial_time}" if added_date else initial_time
            
            dexscreener_link = token.get('dexscreener_link', '#')
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
            initial_mc = format_number(token.get('initial_market_cap', 0)) if token.get('initial_market_cap') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            current_mc = format_number(token.get('current_market_cap', 0)) if token.get('current_market_cap') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            ath_mc = format_number(token.get('ath_market_cap', 0)) if token.get('ath_market_cap') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è ATH –∏ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            ath_percent = token.get('ath_percent', 0)
            curr_percent = token.get('curr_percent', 0)
            
            ath_percent_str = f"+{ath_percent:.1f}%" if ath_percent >= 0 else f"{ath_percent:.1f}%"
            curr_percent_str = f"+{curr_percent:.1f}%" if curr_percent >= 0 else f"{curr_percent:.1f}%"
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ –∏–∑ tracker_db
            emojis = tracker_emojis.get(query, "")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Å—ã–ª–∫–æ–π –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–∏–∫–µ—Ä–∞
            message += f"{i}. [{ticker}]({dexscreener_link}):\n"
            message += f"   Time: {date_time_str} Mcap: {initial_mc}\n"
            message += f"   {ath_percent_str} ATH {ath_mc}\n"
            message += f"   {curr_percent_str} CURR {current_mc}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —ç–º–æ–¥–∑–∏ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å CURR, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            if emojis:
                message += f"   {emojis}\n"
            
            message += "\n"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return ("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", 1, 0)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–∞–Ω–¥–∞—Ö
    if page == total_pages - 1:  # –¢–æ–ª—å–∫–æ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        message += f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/clear` –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏.\n"
        message += f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ `/excel` –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è Excel —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏."
    
    return (message, total_pages, page)