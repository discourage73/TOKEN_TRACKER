from datetime import datetime
from typing import Dict, Any, Optional, Union, List

import logging
logger = logging.getLogger(__name__)

def format_number(value: Union[int, float, str]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    if isinstance(value, (int, float)):
        if value >= 1000000000:
            return f"${value / 1000000000:.2f}B"
        elif value >= 1000000:
            return f"${value / 1000000:.2f}M"
        elif value >= 1000:
            return f"${value / 1000:.2f}K"
        else:
            return f"${value:.2f}"
    elif isinstance(value, str):
        try:
            value = float(value)
            return format_number(value)
        except (ValueError, TypeError):
            return value
    else:
        return "Unknown"

def format_enhanced_message(token_info: Dict[str, Any], initial_data: Optional[Dict[str, Any]] = None) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–∫–µ–Ω–µ."""
    try:
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ–∏—Å–∫ –∞–¥—Ä–µ—Å–∞ –≤ Twitter/X.com
        ticker_address = token_info.get('ticker_address', '')
        twitter_search_link = f"https://twitter.com/search?q={ticker_address}"
        
        message = f"üí∞ *Ticker*: {token_info.get('ticker', 'Unknown')} [üîç]({twitter_search_link})\n"
        message += f"üìù *CA*: `{token_info.get('ticker_address', 'Unknown')}`\n\n"
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Å–∞–π—Ç—ã (–ø–µ—Ä–µ–º–µ—â–µ–Ω –≤–≤–µ—Ä—Ö)
        if 'websites' in token_info and token_info.get('websites'):
            website_links = [f"[{website.get('label', 'Website')}]({website.get('url', '')})" 
                           for website in token_info.get('websites', []) if website.get('url')]
            
            if website_links:
                message += f"üåê *Website*: {' | '.join(website_links)}\n"
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç—ã: {website_links}")
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏ (–ø–µ—Ä–µ–º–µ—â–µ–Ω –≤–≤–µ—Ä—Ö)
        if 'socials' in token_info and token_info.get('socials'):
            social_links = [f"[{social.get('type', '').capitalize()}]({social.get('url', '')})" 
                          for social in token_info.get('socials', []) if social.get('url') and social.get('type')]
            
            if social_links:
                message += f"üì± *Social*: {' | '.join(social_links)}\n\n"
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ—Ü—Å–µ—Ç–∏: {social_links}")
        else:
            message += "\n"  # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å, –µ—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ü—Å–µ—Ç–µ–π
        
        current_time = datetime.now().strftime("%d.%m.%y %H:%M:%S")
        message += f"üí∞ *Market Cap*: {token_info.get('market_cap', 'Unknown')}\n"
        message += f"‚è±Ô∏è _Time: {current_time}_\n"
        message += f"üå± *Token age*: {token_info.get('token_age', 'Unknown')}\n\n"
        
        # –ë–ª–æ–∫ —Å –æ–±—ä–µ–º–∞–º–∏ —Ç–æ—Ä–≥–æ–≤
        volumes_block = ""
        if token_info.get('volume_5m', 'Unknown') != "Unknown":
            volumes_block += f"üìà *Volume (5m)*: {token_info['volume_5m']}\n"
            
        if token_info.get('volume_1h', 'Unknown') != "Unknown":
            volumes_block += f"üìà *Volume (1h)*: {token_info['volume_1h']}\n"
        
        if volumes_block:
            message += volumes_block + "\n"
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞ –¥–ª—è —Å—Å—ã–ª–æ–∫
        ticker_address = token_info.get('ticker_address', '')
        pair_address = token_info.get('pair_address', '')
        
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ GMGN
        gmgn_link = f"https://gmgn.ai/sol/token/{ticker_address}"
        
        # –ë–ª–æ–∫ —Å —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ —Ç–æ—Ä–≥–æ–≤—ã–µ –ø–ª–æ—â–∞–¥–∫–∏
        message += f"üîé [DexScreener]({token_info.get('dexscreener_link', '#')}) | [Axiom]({token_info.get('axiom_link', '#')}) | [GMGN]({gmgn_link})\n\n"
                               
        logger.info("–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        return message
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        return f"ü™ô *Ticker*: {token_info.get('ticker', 'Unknown')}\nüìù *CA*: `{token_info.get('ticker_address', 'Unknown')}`\n\nüí∞ *Market Cap*: {token_info.get('market_cap', 'Unknown')}\n\n_–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–æ–ª–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è_"

def process_token_data(token_data: Dict[str, Any]) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–∫–µ–Ω–µ."""
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    base_token = token_data.get('baseToken', {})
    ticker = base_token.get('symbol', 'Unknown').upper()
    ticker_address = base_token.get('address', 'Unknown')
    pair_address = token_data.get('pairAddress', '')
    chain_id = token_data.get('chainId', '')
    
    # –ü–æ–ª—É—á–∞–µ–º Market Cap, –∏—Å–ø–æ–ª—å–∑—É—è —Ç—É –∂–µ –ª–æ–≥–∏–∫—É —á—Ç–æ –∏ –≤ batch_market_cap
    market_cap = None
    
    # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º fdv (fully diluted value)
    market_cap = token_data.get('fdv')
    if market_cap:
        pass  # –ò—Å–ø–æ–ª—å–∑—É–µ–º fdv
    else:
        # 2. –ü—Ä–æ–±—É–µ–º marketCap
        market_cap = token_data.get('marketCap')
        if not market_cap:
            # 3. –ü—Ä–æ–±—É–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å –∏–∑ —Ü–µ–Ω—ã –∏ liquidity
            price_usd = token_data.get('priceUsd')
            liquidity = token_data.get('liquidity', {})
            if price_usd and liquidity.get('base'):
                try:
                    # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ market cap = price * base_liquidity * 2
                    market_cap = float(price_usd) * float(liquidity['base']) * 2
                except (ValueError, TypeError):
                    pass
            
            # 4. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º liquidity –≤ USD –∫–∞–∫ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
            if not market_cap and liquidity.get('usd'):
                try:
                    market_cap = float(liquidity['usd'])
                except (ValueError, TypeError):
                    pass
    
    raw_market_cap = market_cap  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    market_cap_formatted = format_number(market_cap)
    
    # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫–∏
    dexscreener_link = f"https://dexscreener.com/{chain_id}/{pair_address}"
    axiom_link = f"https://axiom.trade/meme/{pair_address}"
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
    volume_data = token_data.get('volume', {})
    volume_5m = volume_data.get('m5')
    volume_1h = volume_data.get('h1')
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ–±—ä–µ–º—ã
    volume_5m_formatted = format_number(volume_5m)
    volume_1h_formatted = format_number(volume_1h)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
    if token_data.get('pairCreatedAt'):
        delta = datetime.now() - datetime.fromtimestamp(token_data.get('pairCreatedAt')/1000)
        days = delta.days
        hours = delta.seconds // 3600
        minutes = (delta.seconds % 3600) // 60
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –≤–æ–∑—Ä–∞—Å—Ç–∞ —Ç–æ–∫–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –¥–Ω–µ–π, —á–∞—Å–æ–≤ –∏ –º–∏–Ω—É—Ç
        if days > 0:
            if hours > 0 and minutes > 0:
                token_age = f"{days}d {hours}h {minutes}m"
            elif hours > 0:
                token_age = f"{days}d {hours}h"
            else:
                token_age = f"{days}d"
        elif hours > 0:
            if minutes > 0:
                token_age = f"{hours}h {minutes}m"
            else:
                token_age = f"{hours}h"
        else:
            token_age = f"{minutes}m" if minutes > 0 else "< 1m"
    else:
        token_age = "Unknown"
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö –∏ —Å–∞–π—Ç–∞—Ö
    info = token_data.get('info', {})
    websites = info.get('websites', [])
    socials = info.get('socials', [])
    
    return {
        'ticker': ticker,
        'ticker_address': ticker_address,
        'pair_address': pair_address,
        'chain_id': chain_id,
        'market_cap': market_cap_formatted,
        'raw_market_cap': raw_market_cap,
        'volume_5m': volume_5m_formatted,
        'volume_1h': volume_1h_formatted,
        'token_age': token_age,
        'dexscreener_link': dexscreener_link,
        'axiom_link': axiom_link,
        'websites': websites,
        'socials': socials
    }

def format_tokens_list(tokens_data: Dict[str, Dict[str, Any]], page: int = 0, tokens_per_page: int = 10) -> tuple:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –æ—Ç ATH.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (message, total_pages, current_page)
    """
    if not tokens_data:
        return ("–ù–µ—Ç active tokens –≤ —Å–ø–∏—Å–∫–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö.", 1, 0)
    
    # –°–∫—Ä—ã—Ç—ã–µ Tokens –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ
    hidden_info = ""
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
    token_info_list = []
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ —Å–ø–∏—Å–æ–∫
        if isinstance(tokens_data, dict):
            items = tokens_data.items()
        elif isinstance(tokens_data, list):
            items = enumerate(tokens_data)
        else:
            items = []
            
        for query, data in items:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º None –¥–∞–Ω–Ω—ã–µ –∏ —Å–∫—Ä—ã—Ç—ã–µ Tokens
            if not data or not isinstance(data, dict):
                continue
            if data.get('hidden', False):
                continue
                
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ –Ω–∞ None
            token_info = {}
            token_info['query'] = query
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–∫–µ—Ä
            token_info['ticker'] = query
            token_info_data = data.get('token_info')
            if token_info_data and isinstance(token_info_data, dict) and token_info_data.get('ticker'):
                token_info['ticker'] = data['token_info']['ticker']
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑ tracker DB (first_seen)
            token_info['initial_time'] = "Unknown"
            token_info['added_date'] = ""
            
            first_seen = data.get('first_seen')
            if first_seen:
                try:
                    # first_seen –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD HH:MM:SS"
                    import datetime
                    added_datetime = datetime.datetime.strptime(first_seen, "%Y-%m-%d %H:%M:%S")
                    token_info['initial_time'] = added_datetime.strftime("%H:%M:%S")
                    token_info['added_date'] = added_datetime.strftime("%Y-%m-%d")
                    token_info['full_datetime'] = added_datetime.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    # Fallback –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
                    token_info['initial_time'] = str(first_seen)
            elif data.get('added_time'):
                # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç (timestamp)
                try:
                    import datetime
                    added_datetime = datetime.datetime.fromtimestamp(data.get('added_time', 0))
                    token_info['initial_time'] = added_datetime.strftime("%H:%M:%S")
                    token_info['added_date'] = added_datetime.strftime("%Y-%m-%d")
                    token_info['full_datetime'] = added_datetime.strftime("%Y-%m-%d %H:%M:%S")
                except:
                    pass
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø
            token_info['initial_market_cap'] = 0
            initial_data = data.get('initial_data') if data else None
            if initial_data and isinstance(initial_data, dict) and initial_data.get('raw_market_cap'):
                token_info['initial_market_cap'] = initial_data['raw_market_cap']
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø –∏–∑ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç) –∏–ª–∏ –∏–∑ token_info (fallback)
            token_info['current_market_cap'] = 0
            if data and data.get('curr_mcap'):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø –∏–∑ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                token_info['current_market_cap'] = data['curr_mcap']
            elif token_info_data and isinstance(token_info_data, dict) and token_info_data.get('raw_market_cap'):
                # Fallback –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –º–∞—Ä–∫–µ—Ç –∫–∞–ø –∏–∑ token_info
                token_info['current_market_cap'] = token_info_data['raw_market_cap']
            
            # –ü–æ–ª—É—á–∞–µ–º ATH –º–∞—Ä–∫–µ—Ç –∫–∞–ø
            token_info['ath_market_cap'] = data.get('ath_market_cap', 0) if data else 0
            
            # –ï—Å–ª–∏ ATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –º–µ–Ω—å—à–µ –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π –∫–∞–∫ ATH
            if not token_info['ath_market_cap'] or (token_info['initial_market_cap'] > token_info['ath_market_cap']):
                token_info['ath_market_cap'] = token_info['initial_market_cap']
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è ATH –∏ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            token_info['ath_percent'] = 0
            if token_info['initial_market_cap'] and token_info['ath_market_cap'] and token_info['initial_market_cap'] > 0:
                token_info['ath_percent'] = ((token_info['ath_market_cap'] / token_info['initial_market_cap']) - 1) * 100
            
            token_info['curr_percent'] = 0
            if token_info['initial_market_cap'] and token_info['current_market_cap'] and token_info['initial_market_cap'] > 0:
                token_info['curr_percent'] = ((token_info['current_market_cap'] / token_info['initial_market_cap']) - 1) * 100
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ DexScreener
            token_info['dexscreener_link'] = "#"
            if data and token_info_data and isinstance(token_info_data, dict) and token_info_data.get('dexscreener_link'):
                token_info['dexscreener_link'] = token_info_data['dexscreener_link']
            
            token_info_list.append(token_info)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º Tokens –ø–æ –ø—Ä–æ—Ü–µ–Ω—Ç—É —Ä–æ—Å—Ç–∞ ATH (–æ—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –∫ –Ω–∞–∏–º–µ–Ω—å—à–µ–º—É)
        token_info_list.sort(key=lambda x: x.get('ath_percent', 0), reverse=True)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return ("An error occurred –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", 1, 0)
    
    # –†–∞—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
    total_tokens = len(token_info_list)
    total_pages = (total_tokens + tokens_per_page - 1) // tokens_per_page  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –≤–≤–µ—Ä—Ö
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if page < 0:
        page = 0
    elif page >= total_pages and total_pages > 0:
        page = total_pages - 1
    
    # –ù–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    start_idx = page * tokens_per_page
    end_idx = min(start_idx + tokens_per_page, total_tokens)
    
    # Tokens –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_tokens = token_info_list[start_idx:end_idx]
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏—è
    message = f"üìã *–°–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ ({total_tokens} —à—Ç.){hidden_info}*\n"
    message += f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1} –∏–∑ {total_pages}\n\n"
    
    # –ó–∞–≥—Ä—É–∑–∏–º tracker_db –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–æ–¥–∑–∏ —Ç–æ–∫–µ–Ω–æ–≤
    tracker_emojis = {}
    try:
        import sqlite3
        import os
        
        # –ü—É—Ç—å –∫ SQL –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫–µ—Ä–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞)
        TRACKER_DB_PATH = 'tokens_tracker_database.db'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ SQL –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        if os.path.exists(TRACKER_DB_PATH):
            conn = sqlite3.connect(TRACKER_DB_PATH)
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —ç–º–æ–¥–∂–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã tokens
            cursor.execute('SELECT contract, emojis FROM tokens WHERE emojis IS NOT NULL AND emojis != ""')
            rows = cursor.fetchall()
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å —ç–º–æ–¥–∂–∏ (contract –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ query)
            for contract, emojis in rows:
                if emojis:
                    tracker_emojis[contract] = emojis
            
            conn.close()
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(tracker_emojis)} —ç–º–æ–¥–∂–∏ –∏–∑ SQL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        else:
            logger.warning(f"SQL –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö {TRACKER_DB_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —ç–º–æ–¥–∂–∏ –∏–∑ SQL: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    try:
        for i, token in enumerate(page_tokens, start=start_idx + 1):
            ticker = token.get('ticker', 'Unknown')
            query = token.get('query', '')
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
            if token.get('full_datetime'):
                date_time_str = token.get('full_datetime')
            else:
                added_date = token.get('added_date', '')
                initial_time = token.get('initial_time', 'Unknown')
                date_time_str = f"{added_date} {initial_time}" if added_date else initial_time
            
            dexscreener_link = token.get('dexscreener_link', '#')
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª
            initial_mc = format_number(token.get('initial_market_cap', 0)) if token.get('initial_market_cap') else "Unknown"
            current_mc = format_number(token.get('current_market_cap', 0)) if token.get('current_market_cap') else "Unknown"
            ath_mc = format_number(token.get('ath_market_cap', 0)) if token.get('ath_market_cap') else "Unknown"
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã –¥–ª—è ATH –∏ —Ç–µ–∫—É—â–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            ath_percent = token.get('ath_percent', 0)
            curr_percent = token.get('curr_percent', 0)
            
            ath_percent_str = f"+{ath_percent:.1f}%" if ath_percent >= 0 else f"{ath_percent:.1f}%"
            curr_percent_str = f"+{curr_percent:.1f}%" if curr_percent >= 0 else f"{curr_percent:.1f}%"
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∞ –∏–∑ tracker_db
            emojis = tracker_emojis.get(query, "")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ —Å—Å—ã–ª–∫–æ–π –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–∏–∫–µ—Ä–∞
            message += f"{i}. [{ticker}]({dexscreener_link}):\n"
            message += f"   Time: {date_time_str} Mcap: {initial_mc}\n"
            message += f"   {ath_percent_str} ATH {ath_mc}\n"
            message += f"   {curr_percent_str} CURR {current_mc}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —ç–º–æ–¥–∑–∏ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ —Å CURR, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            if emojis:
                message += f"   {emojis}\n"
            
            message += "\n"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return ("An error occurred –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", 1, 0)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–∞–Ω–¥–∞—Ö
    if page == total_pages - 1:  # –¢–æ–ª—å–∫–æ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        message += f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `/clear` –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏.\n"
        message += f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ `/excel` –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è Excel —Ñ–∞–π–ª–∞ —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏."
    
    return (message, total_pages, page)

def format_hotboard_message() -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å HOT BOARD —Ç–æ–∫–µ–Ω–∞–º–∏"""
    import sqlite3
    
    try:
        conn = sqlite3.connect("tokens_tracker_database.db")
        cursor = conn.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ hotboard, —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ ath_multiplier –ø–æ —É–±—ã–≤–∞–Ω–∏—é
        cursor.execute('''
        SELECT contract, ticker, initial_mcap, initial_time, ath_mcap, ath_multiplier
        FROM hotboard 
        ORDER BY ath_multiplier DESC
        ''')
        
        hotboard_data = cursor.fetchall()
        conn.close()
        
        if not hotboard_data:
            return "üî• HOT BOARD\n\n–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç. –î–æ–±–∞–≤—å—Ç–µ Tokens –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."
        
        message = "üî• HOT BOARD\n\n"
        
        for i, (contract, ticker, initial_mcap, initial_time, ath_mcap, ath_multiplier) in enumerate(hotboard_data, 1):
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –º–Ω–æ–∂–∏—Ç–µ–ª—å
            multiplier_str = f"{ath_multiplier:.0f}X" if ath_multiplier else "1X"
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–∏–∫–µ—Ä —Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ DexScreener
            if ticker:
                dexscreener_url = f"https://dexscreener.com/solana/{contract}"
                ticker_display = f"[{ticker}]({dexscreener_url})"
            else:
                ticker_display = "???"
            
            message += f"{i}. *{multiplier_str}* Ticker: {ticker_display}\n"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Called at (initial mcap) –∏ –≤—Ä–µ–º–µ–Ω–∏
            if initial_mcap and initial_time:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º initial_mcap
                if initial_mcap >= 1000000:
                    mcap_formatted = f"${initial_mcap/1000000:.1f}M"
                elif initial_mcap >= 1000:
                    mcap_formatted = f"${initial_mcap/1000:.0f}K"
                else:
                    mcap_formatted = f"${initial_mcap:.0f}"
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è - –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –±–µ–∑ —Å–µ–∫—É–Ω–¥
                try:
                    from datetime import datetime
                    if len(initial_time) > 16:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–µ–∫—É–Ω–¥—ã
                        time_formatted = initial_time[:16]  # –û–±—Ä–µ–∑–∞–µ–º —Å–µ–∫—É–Ω–¥—ã
                    else:
                        time_formatted = initial_time
                except:
                    time_formatted = initial_time
                
                message += f"   ‚îî _Called at {mcap_formatted}_ ‚Ä¢ {time_formatted}\n"
            
            message += "\n"  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ç–æ–∫–µ–Ω–∞–º–∏
        
        return message
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ HOT BOARD: {e}")
        return "üî• HOT BOARD\n\n–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö."